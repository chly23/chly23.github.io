{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/jacman/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/FontAwesome.otf","path":"font/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","path":"font/coveredbyyourgrace-webfont.eot","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","path":"font/coveredbyyourgrace-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","path":"font/coveredbyyourgrace-webfont.woff","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","path":"font/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","path":"font/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.eot","path":"font/fontdiao.eot","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.woff","path":"font/fontdiao.woff","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.ttf","path":"font/fontdiao.ttf","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/author.jpg","path":"img/author.jpg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","path":"img/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nc.svg","path":"img/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nd.svg","path":"img/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/cc-zero.svg","path":"img/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-sa.svg","path":"img/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/cc-by.svg","path":"img/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/favicon.ico","path":"img/favicon.ico","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/scrollup.png","path":"img/scrollup.png","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/jacman.jpg","path":"img/jacman.jpg","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/logo.svg","path":"img/logo.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","path":"img/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/js/gallery.js","path":"js/gallery.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","path":"js/jquery.qrcode-0.12.0.min.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","path":"font/coveredbyyourgrace-webfont.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","path":"font/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.svg","path":"font/fontdiao.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/logo.png","path":"img/logo.png","modified":0,"renderable":1},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","path":"font/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/jacman/source/img/banner.jpg","path":"img/banner.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/jacman/.gitignore","hash":"7d65523f2a5afb69d76824dd1dfa62a34faa3197","modified":1458009994000},{"_id":"source/.DS_Store","hash":"f6036890fc6e0c788ecf976b992d533d36b2fcd4","modified":1458026913000},{"_id":"themes/jacman/LICENSE","hash":"931516aa36c53eb7843c83d82662eb50cc3c4367","modified":1458009994000},{"_id":"themes/jacman/README_zh.md","hash":"0854e4c96f53005f3a47e21af3f8aee361719ce4","modified":1458009994000},{"_id":"themes/jacman/README.md","hash":"79be8a49927c8666f1804d7ccd08af8d3268062a","modified":1458009994000},{"_id":"themes/jacman/_config.yml","hash":"558731fea51575250b313a0c77bf6a504d7170f4","modified":1458009994000},{"_id":"source/_posts/Memcache-最佳实践.md","hash":"278e917dd9c1f40654b3caa59614636fca27c96e","modified":1458031156000},{"_id":"source/_posts/Mysql-文章.md","hash":"0ed63b8d5c5f432f736a6aca34b7839adc0c5cf9","modified":1458036479000},{"_id":"source/_posts/.DS_Store","hash":"7af2e0dd9d8d4456ab2f696ce698286596f13127","modified":1458036086000},{"_id":"source/_posts/Mysql-最左原则.md","hash":"4fd43c4b07b9fe9fb5b4983c3c0f530450a58789","modified":1458037409000},{"_id":"source/_posts/test-md.md","hash":"6b9fa32e6e8ddbbebd0ef6c61c3eec5fa05f639d","modified":1458015100000},{"_id":"source/_posts/PHP-convert-string-to-utf8.md","hash":"bc5495e681a03156c8eb553d55d9be345c92b00e","modified":1458029554000},{"_id":"source/about/index.md","hash":"ff8a053861f029365e6c65d2a4ba044f4b2cb6bf","modified":1458026545000},{"_id":"source/_posts/hello-world.md","hash":"95821ef24d440439ab1eb47ccc07a2542677373f","modified":1458025627000},{"_id":"themes/jacman/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1458009994000},{"_id":"themes/jacman/.git/config","hash":"2d3ae691d19a816889480acb832a3813f5ad7605","modified":1458009994000},{"_id":"themes/jacman/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1458009964000},{"_id":"themes/jacman/.git/index","hash":"879e6bfce6dade3b786b6c19cdc7111ccd26ea0e","modified":1458009994000},{"_id":"themes/jacman/.git/packed-refs","hash":"1c5521a149f76a2ab51ba7171e244397824a9fe9","modified":1458009994000},{"_id":"themes/jacman/layout/archive.ejs","hash":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1458009994000},{"_id":"themes/jacman/layout/category.ejs","hash":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1458009994000},{"_id":"themes/jacman/layout/index.ejs","hash":"75cef2172c286994af412e11ab7f4f5a0daaf1f5","modified":1458009994000},{"_id":"themes/jacman/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1458009994000},{"_id":"themes/jacman/layout/layout.ejs","hash":"5b4289a4526899809b9c2facea535367ff51ba2b","modified":1458009994000},{"_id":"themes/jacman/layout/post.ejs","hash":"3114134775bdde5a83cf14feb019606fa2b2b2be","modified":1458009994000},{"_id":"themes/jacman/layout/page.ejs","hash":"bd6bbf2ea8e183bd835867ff617dc6366b56748c","modified":1458009994000},{"_id":"themes/jacman/layout/tag.ejs","hash":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1458009994000},{"_id":"themes/jacman/languages/default.yml","hash":"eea72d6138497287c0b3f4bd93e4f6f62b7aff37","modified":1458009994000},{"_id":"themes/jacman/languages/zh-CN.yml","hash":"1f3b9d00dd4322352b0c9c82a76dc9865a616d41","modified":1458009994000},{"_id":"themes/jacman/languages/zh-TW.yml","hash":"61a02ba818d641579a86fcd7f5926ab1e6ab5f70","modified":1458009994000},{"_id":"themes/jacman/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1458009964000},{"_id":"themes/jacman/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1458009964000},{"_id":"themes/jacman/.git/hooks/update.sample","hash":"39355a075977d05708ef74e1b66d09a36e486df1","modified":1458009964000},{"_id":"themes/jacman/.git/logs/HEAD","hash":"e32f6f6ea76a194db2d91ff84149f81019e57725","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/douban.ejs","hash":"e3820c36169e88663e6c9177666b2904c1ce47e6","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/category.ejs","hash":"c1fae96b5053da021bcc04ab2ce5c2c8d30de8a2","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/rss.ejs","hash":"0a4b5f2a2e36a1d504fe2e7c6c8372cbb4628aab","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/archive.ejs","hash":"39ea6b7888406fbd1b4cf236ebd718e881493374","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/links.ejs","hash":"e49868063439c2092cdf9a8ec82cc295b0e42f66","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/github-card.ejs","hash":"5c759b6ea214bac56a393247de27e67ce73fb33f","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/tag.ejs","hash":"7e82ad9c916b9ce871b2f65ce8f283c5ba47947b","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/tagcloud.ejs","hash":"10a1001189d5c28ce6d42494563b9637c302b454","modified":1458009994000},{"_id":"themes/jacman/layout/_widget/weibo.ejs","hash":"a31c2b223d0feb2a227e203cac9e5d13b7d328a8","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/after_footer.ejs","hash":"c703b0c25139b8a5f8f9d24a334a07905e2b7987","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/archive.ejs","hash":"2c7395e7563fe016521712a645c28a13f952d52a","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/article.ejs","hash":"261ecacb8456f4cb972632b6a9103860fa63b9a3","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/article_row.ejs","hash":"4cb855d91ece7f67b2ca0992fffa55472d0b9c93","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/analytics.ejs","hash":"697601996220fe0a0f9cd628be67dec3c86ae2aa","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/categories.ejs","hash":"8a52d0344d5bce1925cf586ed73c11192925209b","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/footer.ejs","hash":"32db7e7c8171530d29c3878f387c4438d6057508","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/head.ejs","hash":"761941be4922cd3c177c8130296b909bf7db5c09","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/pagination.ejs","hash":"6146ac37dfb4f8613090bc52b3fc8cfa911a186a","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/mathjax.ejs","hash":"d42994ac696f52ba99c1cbac382cd76d5b04a3e8","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/header.ejs","hash":"18515612344ff048b9372b91b7eef6f3b143801f","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/tags.ejs","hash":"b33b2b5d08f1d53a8de25a95f660f7f1cea7b3cb","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/search.ejs","hash":"1083824a6c6c3df02767f2f3b727aee78ebb76ec","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/sidebar.ejs","hash":"c4f527fff0070fbe65919053a16224412317f40d","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/totop.ejs","hash":"bea5bb7cb9350b8af7d97a8d223af63a5b30ab78","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/tinysou_search.ejs","hash":"06ecddc8a9d40b480fe2e958af1dab857a9d5441","modified":1458009994000},{"_id":"themes/jacman/source/css/style.styl","hash":"a0a45af186a72ae68979bf26f2a5d0d2303189ca","modified":1458009994000},{"_id":"themes/jacman/source/font/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1458009994000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","hash":"a17d0f10534303e40f210c506ebb8703fa23b7de","modified":1458009994000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","hash":"194ccb4acf77a03dc25bcc174edb266143704fec","modified":1458009994000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","hash":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e","modified":1458009994000},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1458009994000},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1458009994000},{"_id":"themes/jacman/source/font/fontdiao.eot","hash":"9544a0d7ba208989302bc4da5a184faeb0e883c9","modified":1458009994000},{"_id":"themes/jacman/source/font/fontdiao.woff","hash":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f","modified":1458009994000},{"_id":"themes/jacman/source/font/fontdiao.ttf","hash":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab","modified":1458009994000},{"_id":"themes/jacman/source/img/author.jpg","hash":"2a292e681b4c6c975eec9c8c356d99647a465542","modified":1458009994000},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1458009994000},{"_id":"themes/jacman/source/img/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1458009994000},{"_id":"themes/jacman/source/img/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1458009994000},{"_id":"themes/jacman/source/img/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1458009994000},{"_id":"themes/jacman/source/img/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1458009994000},{"_id":"themes/jacman/source/img/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1458009994000},{"_id":"themes/jacman/source/img/favicon.ico","hash":"2d22a3e0c7905a894e832c831dd91c29c209c7a5","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1458009994000},{"_id":"themes/jacman/source/img/scrollup.png","hash":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3","modified":1458009994000},{"_id":"themes/jacman/source/img/jacman.jpg","hash":"0ba14a4a5e3be012826fc713c33479912126d34e","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1458009994000},{"_id":"themes/jacman/source/img/logo.svg","hash":"9ae38f7225c38624faeb7b74996efa9de7bf065b","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1458009994000},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1458009994000},{"_id":"themes/jacman/source/js/gallery.js","hash":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1458009994000},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","hash":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1458009994000},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","hash":"57c3987166a26415a71292162690e82c21e315ad","modified":1458009994000},{"_id":"themes/jacman/source/js/totop.js","hash":"cad23c5ea7163d1e5c05a0fd3ef9233469da10cb","modified":1458009994000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","hash":"eabdb262d8e246865dfb56031f01ff6e8d2f9d53","modified":1458009994000},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1458009994000},{"_id":"themes/jacman/source/font/fontdiao.svg","hash":"334a94e6a66a8b089be7315d876bec93efe38d2b","modified":1458009994000},{"_id":"themes/jacman/source/img/logo.png","hash":"fd08d12d1fa147cf894e8f8327e38f1758de32ed","modified":1458009994000},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","hash":"a0ae3697b0ab8c0e8bd3186c80db42abd6d97a8d","modified":1458009994000},{"_id":"themes/jacman/.git/refs/heads/master","hash":"2abfefd62c893e935537348a666f90d4c0dce62a","modified":1458009994000},{"_id":"themes/jacman/.git/objects/pack/pack-1a3a64e748f4ed05750dfbb293f98366dde8fcdc.idx","hash":"f6bcfcc5bd18054de5466e90ade7199ae4bf1dbb","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/article.ejs","hash":"b09e3acea7076e1f01dfe0c2295e19951ea09437","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/catetags.ejs","hash":"0e37bababc8f4659f5b59a552a946b46d89e4158","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/footer.ejs","hash":"b12ec08a5845a3d8c01257614f1dfead879c87d2","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/comment.ejs","hash":"c88bc8f5805173920a5fdd7e9234a850e3d8e151","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/header.ejs","hash":"36a705942b691abe0d643ea8afa339981b32f6f2","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/gallery.ejs","hash":"fafc2501d7e65983b0f5c2b58151ca12e57c0574","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/jiathis.ejs","hash":"d7f5960039ac74924559ab6ba03c64457b8f0966","modified":1458009994000},{"_id":"themes/jacman/layout/_partial/post/pagination.ejs","hash":"7de9c07a4c968429a8088c31a28b7f3a993ded1b","modified":1458009994000},{"_id":"themes/jacman/source/css/_base/public.styl","hash":"f016180726019927b9a835ed01e04d153f27a149","modified":1458009994000},{"_id":"themes/jacman/source/css/_base/font.styl","hash":"c8a0faf43b08e37ad07a5669db76d595da966159","modified":1458009994000},{"_id":"themes/jacman/source/css/_base/variable.styl","hash":"cb652eb83c28a208743fabab92de896f8b7cbf7b","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/article.styl","hash":"c69641b4a34a8c62986b335414413dbde26de25e","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/aside.styl","hash":"506fde1d67ce750452cbe84bee01a19c7d027c5e","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/gallery.styl","hash":"7246809f4ce3166ec1b259bf475cae1a48e29aad","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/footer.styl","hash":"1911613a19b605a58f801c21b03b5d4c83b90f9c","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/duoshuo.styl","hash":"e85f1192283f043115c272a9deb3cb6ced793990","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/header.styl","hash":"5121ceb712be3f2dde98b8b6e589b546e19eab8f","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/helper.styl","hash":"1136600932b97534b88465bf05ef313630b2de3d","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/index.styl","hash":"a72ff14effd276015264f870f47ed8f8413bf5d3","modified":1458009994000},{"_id":"themes/jacman/source/css/_partial/totop.styl","hash":"96363d7c5aaed5f649667fc0752a62620a67e872","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1458009994000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1458009994000},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1458009994000},{"_id":"themes/jacman/source/img/banner.jpg","hash":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74","modified":1458009994000},{"_id":"themes/jacman/.git/logs/refs/heads/master","hash":"e32f6f6ea76a194db2d91ff84149f81019e57725","modified":1458009994000},{"_id":"themes/jacman/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1458009994000},{"_id":"themes/jacman/source/css/_base/highlight/theme.styl","hash":"e3a59bd427ba37a54ead9eeba9a5356b3f720a48","modified":1458009994000},{"_id":"themes/jacman/source/css/_base/highlight/highlight.styl","hash":"91b62bfc58390b0d5db782a75be6965ee3665eb3","modified":1458009994000},{"_id":"themes/jacman/.git/logs/refs/remotes/origin/HEAD","hash":"e32f6f6ea76a194db2d91ff84149f81019e57725","modified":1458009994000},{"_id":"themes/jacman/.git/objects/pack/pack-1a3a64e748f4ed05750dfbb293f98366dde8fcdc.pack","hash":"855730495de2f0759020061f54ce8d2bcf662097","modified":1458009994000},{"_id":"public/baidusitemap.xml","hash":"9700c7e95a4d3f2320e60e016224059f6fc97384","modified":1458037425953},{"_id":"public/atom.xml","hash":"ab7f5370dd0403051ba734be283af750b84a8039","modified":1458037425957},{"_id":"public/about/index.html","hash":"e83024ba0507e24977576a959e6578fd37d80778","modified":1458036492905},{"_id":"public/2016/03/15/PHP-convert-string-to-utf8/index.html","hash":"2b5a01ac69e0bf8c3ff649ed8b826ddaa0fc7642","modified":1458036492906},{"_id":"public/2016/03/15/Mysql-最左原则/index.html","hash":"edda47d415576112c188c8e533a574ef526c6776","modified":1458037425963},{"_id":"public/archives/index.html","hash":"bcf4a48befa09e155d7c7c23bcfbaaf4250d62a4","modified":1458036492906},{"_id":"public/2016/03/14/test-md/index.html","hash":"ceb8908871b652f2b4d0295f9cd71f517f8d369b","modified":1458036492906},{"_id":"public/archives/2016/index.html","hash":"17ff96e37050db40b2c339ebfb7fd3e5c24609d2","modified":1458036492906},{"_id":"public/archives/2016/03/index.html","hash":"fd436de24267fd3e256aa734670f59ba98f0a28d","modified":1458036492906},{"_id":"public/categories/mysql/index.html","hash":"a2a3a971226242dc025d0cb6096ea555d88d8ba0","modified":1458036492906},{"_id":"public/categories/php/index.html","hash":"2e6b07ede8aece016adc07389138c806b4b4cdca","modified":1458036492907},{"_id":"public/tags/memcache/index.html","hash":"085da63b47baf8bdbf42b65997a2e98f9d2c7bc7","modified":1458036492907},{"_id":"public/tags/mysql/index.html","hash":"4307c204f7b92f28b19e80c846aaf16758cb3af9","modified":1458036492907},{"_id":"public/tags/测试/index.html","hash":"869731394ea17090deb67e5802ce145f23eeaf47","modified":1458036492908},{"_id":"public/2016/03/15/Memcache-最佳实践/index.html","hash":"0eb6c3b41720afbdffdb9db6b3789e6e7c9beef9","modified":1458036492908},{"_id":"public/2016/03/15/hello-world/index.html","hash":"34600033beedd0e822c76027bb3e3c5812321107","modified":1458036492908},{"_id":"public/index.html","hash":"cefae8a3b7b7af1e08ca4a3bade1331083de1c30","modified":1458037425963},{"_id":"public/2016/03/15/Mysql-文章/index.html","hash":"c937bb2322b6bf1d85179a4aaa3b330e4e60d9a8","modified":1458036492926},{"_id":"public/tags/haha/index.html","hash":"e6a401be4fc6bc183e5995ea5b7d8990ea97833c","modified":1458036492926},{"_id":"public/tags/php/index.html","hash":"b092ec8ab8807a589d0d3a205c8fbc855b878f62","modified":1458036492926},{"_id":"public/font/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1458036492951},{"_id":"public/font/coveredbyyourgrace-webfont.eot","hash":"a17d0f10534303e40f210c506ebb8703fa23b7de","modified":1458036492951},{"_id":"public/font/coveredbyyourgrace-webfont.ttf","hash":"194ccb4acf77a03dc25bcc174edb266143704fec","modified":1458036492952},{"_id":"public/font/coveredbyyourgrace-webfont.woff","hash":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e","modified":1458036492952},{"_id":"public/font/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1458036492952},{"_id":"public/font/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1458036492952},{"_id":"public/font/fontdiao.eot","hash":"9544a0d7ba208989302bc4da5a184faeb0e883c9","modified":1458036492952},{"_id":"public/font/fontdiao.woff","hash":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f","modified":1458036492952},{"_id":"public/font/fontdiao.ttf","hash":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab","modified":1458036492953},{"_id":"public/img/author.jpg","hash":"2a292e681b4c6c975eec9c8c356d99647a465542","modified":1458036492953},{"_id":"public/img/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1458036492953},{"_id":"public/img/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1458036492953},{"_id":"public/img/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1458036492954},{"_id":"public/img/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1458036492954},{"_id":"public/img/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1458036492954},{"_id":"public/img/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1458036492954},{"_id":"public/img/favicon.ico","hash":"2d22a3e0c7905a894e832c831dd91c29c209c7a5","modified":1458036492954},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1458036492954},{"_id":"public/img/scrollup.png","hash":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3","modified":1458036492954},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1458036492954},{"_id":"public/img/jacman.jpg","hash":"0ba14a4a5e3be012826fc713c33479912126d34e","modified":1458036492954},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1458036492954},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1458036492955},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1458036492955},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1458036492955},{"_id":"public/img/logo.svg","hash":"9ae38f7225c38624faeb7b74996efa9de7bf065b","modified":1458036492955},{"_id":"public/img/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1458036492955},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1458036492955},{"_id":"public/font/coveredbyyourgrace-webfont.svg","hash":"eabdb262d8e246865dfb56031f01ff6e8d2f9d53","modified":1458036494440},{"_id":"public/font/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1458036494446},{"_id":"public/font/fontdiao.svg","hash":"334a94e6a66a8b089be7315d876bec93efe38d2b","modified":1458036494449},{"_id":"public/img/logo.png","hash":"fd08d12d1fa147cf894e8f8327e38f1758de32ed","modified":1458036494449},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1458036494455},{"_id":"public/js/gallery.js","hash":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1458036494455},{"_id":"public/js/jquery.imagesloaded.min.js","hash":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1458036494455},{"_id":"public/js/totop.js","hash":"cad23c5ea7163d1e5c05a0fd3ef9233469da10cb","modified":1458036494456},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1458036494456},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1458036494456},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1458036494456},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1458036494456},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1458036494456},{"_id":"public/css/style.css","hash":"ace9c3df88af85f862060a4cdd5d4716c9a2e5fc","modified":1458036494456},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1458036494456},{"_id":"public/js/jquery.qrcode-0.12.0.min.js","hash":"57c3987166a26415a71292162690e82c21e315ad","modified":1458036494457},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1458036494457},{"_id":"public/js/jquery-2.0.3.min.js","hash":"a0ae3697b0ab8c0e8bd3186c80db42abd6d97a8d","modified":1458036494458},{"_id":"public/font/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1458036494460},{"_id":"public/img/banner.jpg","hash":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74","modified":1458036494461}],"Category":[{"name":"mysql","_id":"cilt9a4tp0006rxzj9hovlijk"},{"name":"php","_id":"cilt9a4u7000frxzjs87tlmsv"}],"Data":[],"Page":[{"title":"about","date":"2016-03-15T07:21:45.000Z","_content":"to be writen\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2016-03-15 15:21:45\n---\nto be writen\n","updated":"2016-03-15T07:22:25.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cilt9a4t20001rxzj19e9mlf0","content":"<p>to be writen</p>\n","excerpt":"","more":"<p>to be writen</p>\n"}],"Post":[{"title":"Memcache 最佳实践","date":"2016-03-15T08:37:11.000Z","_content":"1、memcached的基本设置 \n 1）启动Memcache的服务器端 \n  # /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid\n\n-d选项是启动一个守护进程， \n-m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB， \n-u是运行Memcache的用户，我这里是root， \n-l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200， \n-p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口， \n-c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定， \n-P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，\n\n 2）如果要结束Memcache进程，执行：\n\n # kill `cat /tmp/memcached.pid`\n\n哈希算法将任意长度的二进制值映射为固定长度的较小二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。如果散列一段明文而且哪怕只更改该\n\n段落的一个字母，随后的哈希都将产生不同的值。要找到散列为同一个值的两个不同的输入，在计算上是不可能的。\n\n2、一致性Hash算法的目的有两点：一是节点变动后其他节点受影响尽可能小；二是节点变动后数据重新分配尽可能均衡 。\n\n3、为什么要运行 memcached ？\n\n如果网站的高流量很大并且大多数的访问会造成数据库高负荷的状况下，使用 memcached 能够减轻数据库的压力。\n\n4、适用memcached的业务场景？\n\n1）如果网站包含了访问量很大的动态网页，因而数据库的负载将会很高。由于大部分数据库请求都是读操作，那么memcached可以显著地减小数据库负载。\n\n2）如果数据库服务器的负载比较低但CPU使用率很高，这时可以缓存计算好的结果（ computed objects ）和渲染后的网页模板（enderred templates）。\n\n3）利用memcached可以缓存session数据、临时数据以减少对他们的数据库写操作。\n\n4）缓存一些很小但是被频繁访问的文件。\n\n5）缓存Web 'services'（非IBM宣扬的Web Services，译者注）或RSS feeds的结果.。\n\n5、不适用memcached的业务场景？\n\n1）缓存对象的大小大于1MB\n\nMemcached本身就不是为了处理庞大的多媒体（large media）和巨大的二进制块（streaming huge blobs）而设计的。\n\n2）key的长度大于250字符\n\n3）虚拟主机不让运行memcached服务\n\n     如果应用本身托管在低端的虚拟私有服务器上，像vmware, xen这类虚拟化技术并不适合运行memcached。Memcached需要接管和控制大块的内存，如果memcached管理的内存\n\n被OS或 hypervisor交换出去，memcached的性能将大打折扣。\n\n4）应用运行在不安全的环境中\n\nMemcached为提供任何安全策略，仅仅通过telnet就可以访问到memcached。如果应用运行在共享的系统上，需要着重考虑安全问题。\n\n5）业务本身需要的是持久化数据或者说需要的应该是database\n\n6、能够遍历memcached中所有的item吗？\n\n不能，这个操作的速度相对缓慢且阻塞其他的操作（这里的缓慢时相比memcached其他的命令）。memcached所有非调试（non-debug）命令，例如add, set, get, fulsh等无论\n\nmemcached中存储了多少数据，它们的执行都只消耗常量时间。任何遍历所有item的命令执行所消耗的时间，将随着memcached中数据量的增加而增加。当其他命令因为等待（遍历所\n\n有item的命令执行完毕）而不能得到执行，因而阻塞将发生。\n\n集群的相关问题\n\n7、memcached是怎么工作的？\n\nMemcached的高性能源于两阶段哈希（two-stage hash）结构。Memcached就像一个巨大的、存储了很多<key,value>对的哈希表。通过key，可以存储或查询任意的数据。 客户端\n\n可以把数据存储在多台memcached上。当查询数据时，客户端首先参考节点列表计算出key的哈希值（阶段一哈希），进而选中一个节点；客户端将请求发送给选中的节点，然后\n\nmemcached节点通过一个内部的哈希算法（阶段二哈希），查找真正的数据（item）并返回给客户端。从实现的角度看，memcached是一个非阻塞的、基于事件的服务器程序。\n\n8、memcached最大的优势是什么？\n\nMemcached最大的好处就是它带来了极佳的水平可扩展性，特别是在一个巨大的系统中。由于客户端自己做了一次哈希，那么我们很容易增加大量memcached到集群中。memcached\n\n之间没有相互通信，因此不会增加 memcached的负载；没有多播协议，不会网络通信量爆炸（implode）。\n\n9、memcached和MySQL的query cache相比，有什么优缺点？\n\n缺点：\n\n1）相比MySQL的query cache，把memcached引入应用中需要不少的工作量。MySQL的query cache，可以自动地缓存SQL查询的结果，被缓存的SQL查询可以被反复、快速的执行。\n\n优点：\n\n1）当修改表时，MySQL的query cache会立刻被刷新（flush）。当写操作很频繁时，MySQL的query cache会经常让所有缓存数据都失效。\n\n2）在多核CPU上，MySQL的query cache会遇到扩展问题（scalability issues）。在多核CPU上，query cache会增加一个全局锁（global lock）, 由于需要刷新更多的缓存数据，速度\n\n会变得更慢。\n\n3）在MySQL的query cache中，是不能存储任意的数据的（只能是SQL查询结果）。利用memcached，我们可以搭建出各种高效的缓存。比如，可以执行多个独立的查询，构建出一个\n\n用户对象（user object），然后将用户对象缓存到memcached中。而query cache是SQL语句级别的，不可能做到这一点。在小的网站中，query cache会有所帮助，但随着网站规模的\n\n增加，query cache的弊将大于利。\n\n4）query cache能够利用的内存容量受到MySQL服务器空闲内存空间的限制。给数据库服务器增加更多的内存来缓存数据，固然是很好的。但是，有了memcached，只要您有空闲的内\n\n存，都可以用来增加memcached集群的规模，然后您就可以缓存更多的数据。\n\n10、memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？\n\n1）首先，local cache面临着严重的内存限制，能够利用的内存容量受到（单台）服务器空闲内存空间的限制。\n\n2）local cache有一点比memcached和query cache都要好，那就是它不但可以存储任意的数据，而且没有网络存取的延迟。因此，local cache的数据查询更快。考虑把highly\n\ncommon的数据放在local cache中吧。如果每个页面都需要加载一些数量较少的数据，可以考虑把它们放在local cached。\n\n3）local cache缺少集体失效（group invalidation）的特性。在memcached集群中，删除或更新一个key会让所有的观察者觉察到。但是在local cache中, 我们只能通知所有的服务器\n\n刷新cache（很慢，不具扩展性）或者仅仅依赖缓存超时失效机制。\n\n11、memcached的cache机制是怎样的？\n\nMemcached主要的cache机制是LRU（最近最少用）算法+超时失效。当您存数据到memcached中，可以指定该数据在缓存中可以呆多久Which is forever, or some time in the\n\nfuture。如果memcached的内存不够用了，过期的slabs会优先被替换，接着就轮到最老的未被使用的slabs。\n\n12、memcached如何实现冗余机制？\n\n不实现！Memcached应该是应用的缓存层，从设计本身来京就不带有任何冗余机制。如果一个memcached节点失去了所有数据，应该可以从数据源（比如数据库）再次获取到数据。应\n\n用系统应该可以容忍节点的失效。如果担心节点失效会大大加重数据库的负担，那么可以采取一些办法。比如您可以增加更多的节点（来减少丢失一个节点的影响），热备节点（在其他节\n\n点down了的时候接管IP）等等。\n\n13、memcached如何处理容错的？\n\n在节点失效的情况下，集群没有必要做任何容错处理。如果发生了节点失效，应对的措施完全取决于用户。\n\n节点失效时，下面列出几种方案供您选择：\n\n1）忽略它！ 在失效节点被恢复或替换之前，还有很多其他节点可以应对节点失效带来的影响。\n\n2）把失效的节点从节点列表中移除。做这个操作千万要小心！在默认情况下（余数式哈希算法），客户端添加或移除节点，会导致所有的缓存数据不可用！因为哈希参照的节点列表变化\n\n了，大部分key会因为哈希值的改变而被映射到（与原来）不同的节点上。\n\n3）启动热备节点，接管失效节点所占用的IP。这样可以防止哈希紊乱（hashing chaos）。\n\n4）如果希望添加和移除节点，而不影响原先的哈希结果，可以使用一致性哈希算法（consistent hashing）。\n\n5）两次哈希（reshing）。当客户端存取数据时，如果发现一个节点down了，就再做一次哈希（哈希算法与前一次不同），重新选择另一个节点（需要注意的时，客户端并没有把down\n\n的节点从节点列表中移除，下次还是有可能先哈希到它）。如果某个节点时好时坏，两次哈希的方法就有风险了，好的节点和坏的节点上都可能存在脏数据（stale data）。\n\n14、如何将memcached中item批量导入导出？\n\n不应该这样做！Memcached是一个非阻塞的服务器。任何可能导致memcached暂停或瞬时拒绝服务的操作都应该值得深思熟虑。向memcached中批量导入数据往往不是您真正想要\n\n的！想象看，如果缓存数据在导出导入之间发生了变化，您就需要处理脏数据了；如果缓存数据在导出导入之间过期了，您又怎么处理这些数据呢？\n\n因此，批量导出导入数据并不像想象中的那么有用。不过在一个场景倒是很有用。如果您有大量的从不变化 的数据，并且希望缓存很快热（warm）起来，批量导入缓存数据是很有帮助\n\n的。\n\n15、但是我确实需要把memcached中的item批量导出导入，怎么办？？\n\n如果需要批量导出和导入，最可能的原因一般是重新生成缓存数据需要消耗很长的时间或者数据库坏了让您饱受痛苦。\n\n如果一个memcached节点down了让您很痛苦，那么必须对数据库做一些优化工作。比如处理\"惊群\"问题（ memcached节点都失效了，反复的查询让数据库不堪重负）或者存在优化不\n\n好的查询等。Memcached 并不是逃避优化查询的借口和方案。\n\n这里给出一些提示：\n\n使用MogileFS（或者CouchDB等类似的软件）在存储item，把item计算出来并dump到磁盘上。MogileFS可以很方便地覆写item，并提供快速地访问。甚至可以把MogileFS中的item\n\n缓存在memcached中，这样可以加快读取速度。 MogileFS+Memcached的组合可以加快缓存不命中时的响应速度，提高网站的可用性。\n\n重新使用MySQL。MySQL的 InnoDB主键查询速度非常快。如果大部分缓存数据都可以放到VARCHAR字段中，那么主键查询的性能将更好。从memcached中按key查询几乎等价于\n\nMySQL的主键查询：将key 哈希到64-bit的整数，然后将数据存储到MySQL中。您可以把原始（不做哈希）的key存储都普通的字段中，然后建立二级索引来加快查询...key被动地失效，\n\n批量删除失效的key，等等。\n\n16、memcached是如何做身份验证的？\n\n没有身份认证机制！memcached是运行在应用下层的软件（身份验证应该是应用上层的职责）。memcached的客户端和服务器端之所以是轻量级的，部分原因就是完全没有实现身份验\n\n证机制。这样，memcached可以很快地创建新连接，服务器端也无需任何配置。如果您希望限制访问，您可以使用防火墙，或者让memcached监听unix domain socket。\n\n17、memcached的多线程是什么？如何使用它们？\n\n线程就是定律（threads rule）！在Steven Grimm和Facebook的努力下，memcached 1.2及更高版本拥有了多线程模式。多线程模式允许memcached能够充分利用多个CPU，并在\n\nCPU之间共享所有的缓存数据。memcached使用一种简单的锁机制来保证数据更新操作的互斥。相比在同一个物理机器上运行多个memcached实例，这种方式能够更有效地处理multi\n\ngets。如果系统的负载并不重，那么不需要启用多线程工作模式。如果您在运行一个拥有大规模硬件的、庞大的网站，将体验到看到多线程的好处。更多信息请参见：\n\nhttp://code.sixapart.com/svn/memcached/trunk/server/doc/threads.txt 。\n\n简单地总结一下：命令解析（memcached在这里花了大部分时间）可以运行在多线程模式下。memcached内部对数据的操作是基于很多全局锁的（因此这部分工作不是多线程的）。未\n\n来对多线程模式的改进，将移除大量的全局锁，提高memcached在负载极高的场景下的性能。\n\n18、memcached能接受的key的最大长度是多少？\n\nmemcached能接受的key的最大长度是250个字符。需要注意的是，250是memcached服务器端内部的限制。如果使用的Memcached客户端支持\"key的前缀\"或类似特性，那么key\n\n（前缀+原始key）的最大长度是可以超过250个字符的。推荐使用较短的key，这样可以节省内存和带宽。\n\n19、memcached对item的过期时间有什么限制？\n\nitem对象的过期时间最长可以达到30天。memcached把传入的过期时间（时间段）解释成时间点后，一旦到了这个时间点，memcached就把item置为失效状态，这是一个简单但\n\nobscure的机制。\n\n20、memcached最大能存储多大的单个item？\n\nmemcached最大能存储1MB的单个item。如果需要被缓存的数据大于1MB，可以考虑在客户端压缩或拆分到多个key中。\n\n21、为什么单个item的大小被限制在1M byte之内？\n\n简单的回答：因为内存分配器的算法就是这样的。\n\n详细的回答：\n\n1）Memcached的内存存储引擎，使用slabs来管理内存。内存被分成大小不等的slabs chunks（先分成大小相等的slabs，然后每个slab被分成大小相等chunks，不同slab的chunk大小\n\n是不相等的）。chunk的大小依次从一个最小数开始，按某个因子增长，直到达到最大的可能值。如果最小值为400B，最大值是1MB，因子是1.20，各个slab的chunk的大小依次是：\n\nslab1 - 400B；slab2 - 480B；slab3 - 576B ...slab中chunk越大，它和前面的slab之间的间隙就越大。因此，最大值越大，内存利用率越低。Memcached必须为每个slab预先分配内\n\n存，因此如果设置了较小的因子和较大的最大值，会需要为Memcached提供更多的内存。\n\n2）不要尝试向memcached中存取很大的数据，例如把巨大的网页放到mencached中。因为将大数据load和unpack到内存中需要花费很长的时间，从而导致系统的性能反而不好。如果\n\n确实需要存储大于1MB的数据，可以修改slabs.c：POWER_BLOCK的值，然后重新编译memcached；或者使用低效的malloc/free。另外，可以使用数据库、MogileFS等方案代替\n\nMemcached系统。\n\n22、可以在不同的memcached节点上使用大小不等的缓存空间吗？如果这么做之后，memcached能够更有效地使用内存吗？\n\nMemcache客户端仅根据哈希算法来决定将某个key存储在哪个节点上，而不考虑节点的内存大小。因此，可以在不同的节点上使用大小不等的内存作为缓存空间。但是一般可以这样做\n\n：拥有较多内存的节点上可以运行多个memcached实例，每个实例使用的内存跟其他节点上的实例相同。\n\n23、什么是二进制协议，是否需要关注？\n\n二进制协议尝试为端提供一个更有效的、可靠的协议，减少客户端/服务器端因处理协议而产生的CPU时间。根据Facebook的测试，解析ASCII协议是memcached中消耗CPU时间最多的\n\n环节。\n\n24、memcached的内存分配器是如何工作的？为什么不适用malloc/free！？为何要使用slabs？\n\n实际上，这是一个编译时选项。默认会使用内部的slab分配器，而且确实应该使用内建的slab分配器。最早的时候，memcached只使用malloc/free来管理内存。然而，这种方式不能与\n\nOS的内存管理以前很好地工作。反复地malloc/free造成了内存碎片，OS最终花费大量的时间去查找连续的内存块来满足malloc的请求，而不是运行memcached进程。slab分配器就是\n\n为了解决这个问题而生的。内存被分配并划分成chunks，一直被重复使用。因为内存被划分成大小不等的slabs，如果item的大小与被选择存放它的slab不是很合适的话，就会浪费一些内存。\n\n25、memcached是原子的吗？\n\n所有的被发送到memcached的单个命令是完全原子的。如果您针对同一份数据同时发送了一个set命令和一个get命令，它们不会影响对方。它们将被串行化、先后执行。即使在多线程模\n\n式，所有的命令都是原子的。然是，命令序列不是原子的。如果首先通过get命令获取了一个item，修改了它，然后再把它set回memcached，系统不保证这个item没有被其他进程\n\n（process，未必是操作系统中的进程）操作过。memcached 1.2.5以及更高版本，提供了gets和cas命令，它们可以解决上面的问题。如果使用gets命令查询某个key的item，\n\nmemcached会返回该item当前值的唯一标识。如果客户端程序覆写了这个item并想把它写回到memcached中，可以通过cas命令把那个唯一标识一起发送给memcached。如果该item\n\n存放在memcached中的唯一标识与您提供的一致，写操作将会成功。如果另一个进程在这期间也修改了这个item，那么该item存放在memcached中的唯一标识将会改变，写操作就会\n\n失败。\n\n性能和客户端库方面的问题\n\n26、memcached没有我的database快，为什么？\n\n在一对一比较中，memcached可能没有SQL查询快。但是，这不是memcached的设计目标。Memcached的目标是可伸缩性。当连接和请求增加的时候，memcached的性能将比\n\n大多数数据库查询好。可以先在高负载的环境（并发的连接和请求）中测试您的代码，然后再决定memcached是否适合您。\n\n27、使用不同的客户端库，可以访问到memcached中相同的数据吗？\n\n从技术上说，是可以的。但是可能会遇到下面三个问题：\n\n1）不同的库采用不同的方式序列化数据。举个例子，perl的Cache::Memcached使用Storable来序列化结构复杂的数据（比如hash references, objects, 等）。其他语言的客户端库很\n\n可能不能读取这种格式的数据。如果您要存储复杂的数据并且想被多种客户端库读取，那么您应该以简单的string格式来存储，并且这种格式可以被JSON、XML等外部库解析。\n\n2）从某个客户端来的数据被压缩了，从另一个客户端来的却没被压缩。\n\n3）各个客户端库可能使用不同的哈希算法（阶段一哈希）。在连接到多个memcached服务器端的情况下，客户端库根据自身实现的哈希算法把key映射到某台memcached上。正是因为\n\n不同的客户端库使用不同的哈希算法，所以被Perl客户端库映射到memcached A的key，可能又会被Python客户端库映射到memcached B，等等。Perl客户端库还允许为每台\n\nmemcached指定不同的权重（weight），这也是导致这个问题的一个因素。\n\n28、什么是一致性哈希的客户端？\n\n这里有一篇文章很好地解释了它的用处：http://www.last.fm/user/RJ/journal/2007/04/10/392555 。\n\n客户端可以通过\"前缀\"来给key设置一个域（命名空间）。例如，在一个共享主机的环境中，可以将客户姓名作为\"前缀\"，为key创建一个特定的域。在存储数据的时候，\"前缀\"可以用在\n\nkey上，但是不应该参与哈希计算。目前，memcached自己还没有实现针对复杂结构数据的序列化方法，JSON则是一种被广泛使用的对象序列化格式。\n\n哈希 / 键分布\n\n29、什么时候失效的数据项会从缓存中删除？\n\nmemcached 使用懒失效，当客户端请求数据项时， memcached 在返回数据前会检查失效时间来确定数据项是否已经失效。同样地，当添加一个新的数据项时，如果缓存已经满了， memcached 就会先替换失效的数据项，然后才是缓存中最少使用的数据项。\n\n命名空间\n\n30、memcached 不支持命名空间。以下提供几种模仿命名空间的方式：\n\n1）用键的前缀模仿命名空间：在真实的键之前加入有意义的前缀。\n\n2）用命名空间删除数据项：尽管 memcached 不支持使用任何类型的通配符或命名空间来完成删除操作，但是可以采用一些技巧来替代：\n\n在 PHP 中使用一个叫 foo 的命名空间：$ns_key = $memcache->get(\"foo_namespace_key\");\n\n// if not set, initialize it\n\nif($ns_key=false) $memcache->set(\"foo_namespace_key\", rand(1, 10000));\n\n$my_key = \"foo_\".$ns_key.\"_12345\";\n\n清除命名空间：$memcache->increment(\"foo_namespace_key\");\n\n应用设计\n\n31、在设计应用时，可以通过Memcached缓存那些内容？\n\n1）缓存简单的查询结果：查询缓存存储了给定查询语句对应的整个结果集，最合适缓存那些经常被用到，但不会改变的 SQL 语句对查询到的结果集，比如载入特定的过滤内容。\n\n$key = md5('SELECT * FROM rest_of_sql_statement_goes_here');\n\nif ($memcache->get($key)) {\n\n      ` return $memcache->get($key);`\n\n}else {\n\n    ` // Run the query and transform the result data into your final dataset form`\n\n    ` $result = $query_results_mangled_into_most_likely_an_array`\n\n     ` $memcache->set($key, $result, TRUE, 86400); // Store the result of the query for a day`\n\n    ` return $result;`\n\n}\n\n记住，如果查询语句对应的结果集改变，该结果集不会展现出来。这种方法不总是有用，但它确实让工作变得比较快。\n\n2）缓存简单的基于行的查询结果：基于行的缓存会检查缓存数据key的列表，那些在缓存中的行可以直接被取出，不在缓存中的行将会从数据库中取出并以唯一的键为标识缓存起来，最\n\n后加入到最终的数据集中返回。随着时间的推移，大多数数据都会被缓存，这也意味着相比与数据库，查询语句会更多地从 memcached 中得到数据行。如果数据是相当静态的，我们可\n\n以设置一个较长的缓存时间。\n\n基于行的缓存模式对下面这种搜索情况特别有用：数据集本身很大或是数据集是从多张表中得到，而数据集取决于查询的输入参数但是查询的结果集之间的有重复部分。\n\n比如，如果你有用户 A ， B ， C ， D ， E 的数据集。你去点击一张显示用户 A ， B ， E 信息的页面。首先， memcached 得到 3 个不同的键，每个对应一个用户去缓存中查找，全部未\n\n命中。然后就到数据库中用 SQL 查询得到 3 个用户的数据行，并缓存他们。\n\n现在，你又去点击另一张显示显示 C ， D ， E 信息的页面。当你去查找 memcached 时， C ， D 的数据并没有被命中，但我们命中了 E 的数据。然后从数据库得到 C ， D 的行数据，缓\n\n存在 memcached 中。至此以后，无论这些用户信息怎样地排列组合，任何关于 A ， B ， C ， D ， E 信息的页面都可以从 memcached 得到数据了。\n\n3）缓存的不只是 SQL 数据，可以缓存最终完成的部分显示页面，以节省CPU计算时间\n\n例如正在制作一张显示用户信息的页面，你可能得到一段关于用户的信息（姓名，生日，家庭住址，简介），然后你可能会将 XML 格式的简介信息转化为 HTML 格式或做其他的一些工\n\n作。相比单独存储这些属性，你可能更愿意存储经过渲染的数据块。那时你就可以简单地取出被预处理后的 HTML 直接填充在页面中，这样节省了宝贵的 CPU 时间。\n\n32、使用分层的缓存\n\nmemcached 可以高速处理大量的缓存数据，但是还是要根据系统的情况考虑维护多层的缓存结构。例如除了memcached缓存之外，还可以通过本地缓存（如ehcache、oscache等）建\n\n立起多级缓存。例如，可以采用本地缓存缓存一些基本数据，例如少量但访问频繁的数据（如产品分类，连接信息，服务器状态变量，应用配置变量等），缓存这些数据并让他们尽可能的\n\n接近处理器是有意义的 , 这样可以帮助减少生成页面的时间，并且在 memcached 失效的情况下可以增加可靠性。\n\n33、当数据更新时需要更新缓存\n\n用户编辑了自己的信息，当保存信息到数据库时，需要更新缓存中的数据或是简单地删除老的数据。如果马上更新数据，要防止从数据库读取那些刚刚更新过的数据。当用户习惯性地重新\n\n载入自己的用户信息来确认是否修改成功时，数据将从缓存中直接取出，这时他们获得了最新的数据。\n\n34、模拟带锁的添加命令\n\n如果你实在需要锁，你可以通过“添加”命令模仿锁的功能。尽管在未命中的情况下它不是那么有用，但如果你用它缓存平常的数据（应用服务器池的元数据）那还是有用的。\n\n比如，你要更新键 A 。\n\n1. 添加一个 \"lock:A\" 的键，这个键有一个持续几秒的过期时间（足够长以使你能完成计算和更新，也不要很长，因为如果锁进程挂了，这个键不会立即释放）\n\n2. 如果添加操作成功了，你就拥有了锁：从缓存获取键 A 的数据；利用客户端程序更改数据；更新缓存键 A 的数据；删除键 \"lock:A\" 。如果你不需要立即再次更新，就让它存活直到失效。\n\n3. 如果添加操作失败，说明有人获取了锁。这时让应用做些合适的事，比如返回老数据，等待后重试，或是其他的。\n\n以上这些操作类似 MySQL 将 GET_LOCK 的 timeout 值设置成 0 。没有办法在 memcached 中通过互斥锁模拟 GET_LOCK() 的 timeout 操作。\n\n35、预热你的缓存\n\n如果你有一个很高访问率的站点，并且你正想加入故障恢复功能或是其他全新的功能，你最终可能会碰到空缓存的问题。一开始缓存是空的，然后一大群人点击你的站点，在填充缓存的过\n\n程中，你的数据库可能会承受不住压力。为了解决这一问题，你可以试试任何可行的方法来 \" 温暖 \" 你的Memcached。方法：可以写一些脚本来缓存通用的页面；也可以写一个命令行工\n\n具来填充缓存。你可以在高峰时刻在缓存里填充一些内容。\n\n","source":"_posts/Memcache-最佳实践.md","raw":"---\ntitle: Memcache 最佳实践\ndate: 2016-03-15 16:37:11\ntags: memcache\n---\n1、memcached的基本设置 \n 1）启动Memcache的服务器端 \n  # /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid\n\n-d选项是启动一个守护进程， \n-m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB， \n-u是运行Memcache的用户，我这里是root， \n-l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200， \n-p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口， \n-c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定， \n-P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，\n\n 2）如果要结束Memcache进程，执行：\n\n # kill `cat /tmp/memcached.pid`\n\n哈希算法将任意长度的二进制值映射为固定长度的较小二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。如果散列一段明文而且哪怕只更改该\n\n段落的一个字母，随后的哈希都将产生不同的值。要找到散列为同一个值的两个不同的输入，在计算上是不可能的。\n\n2、一致性Hash算法的目的有两点：一是节点变动后其他节点受影响尽可能小；二是节点变动后数据重新分配尽可能均衡 。\n\n3、为什么要运行 memcached ？\n\n如果网站的高流量很大并且大多数的访问会造成数据库高负荷的状况下，使用 memcached 能够减轻数据库的压力。\n\n4、适用memcached的业务场景？\n\n1）如果网站包含了访问量很大的动态网页，因而数据库的负载将会很高。由于大部分数据库请求都是读操作，那么memcached可以显著地减小数据库负载。\n\n2）如果数据库服务器的负载比较低但CPU使用率很高，这时可以缓存计算好的结果（ computed objects ）和渲染后的网页模板（enderred templates）。\n\n3）利用memcached可以缓存session数据、临时数据以减少对他们的数据库写操作。\n\n4）缓存一些很小但是被频繁访问的文件。\n\n5）缓存Web 'services'（非IBM宣扬的Web Services，译者注）或RSS feeds的结果.。\n\n5、不适用memcached的业务场景？\n\n1）缓存对象的大小大于1MB\n\nMemcached本身就不是为了处理庞大的多媒体（large media）和巨大的二进制块（streaming huge blobs）而设计的。\n\n2）key的长度大于250字符\n\n3）虚拟主机不让运行memcached服务\n\n     如果应用本身托管在低端的虚拟私有服务器上，像vmware, xen这类虚拟化技术并不适合运行memcached。Memcached需要接管和控制大块的内存，如果memcached管理的内存\n\n被OS或 hypervisor交换出去，memcached的性能将大打折扣。\n\n4）应用运行在不安全的环境中\n\nMemcached为提供任何安全策略，仅仅通过telnet就可以访问到memcached。如果应用运行在共享的系统上，需要着重考虑安全问题。\n\n5）业务本身需要的是持久化数据或者说需要的应该是database\n\n6、能够遍历memcached中所有的item吗？\n\n不能，这个操作的速度相对缓慢且阻塞其他的操作（这里的缓慢时相比memcached其他的命令）。memcached所有非调试（non-debug）命令，例如add, set, get, fulsh等无论\n\nmemcached中存储了多少数据，它们的执行都只消耗常量时间。任何遍历所有item的命令执行所消耗的时间，将随着memcached中数据量的增加而增加。当其他命令因为等待（遍历所\n\n有item的命令执行完毕）而不能得到执行，因而阻塞将发生。\n\n集群的相关问题\n\n7、memcached是怎么工作的？\n\nMemcached的高性能源于两阶段哈希（two-stage hash）结构。Memcached就像一个巨大的、存储了很多<key,value>对的哈希表。通过key，可以存储或查询任意的数据。 客户端\n\n可以把数据存储在多台memcached上。当查询数据时，客户端首先参考节点列表计算出key的哈希值（阶段一哈希），进而选中一个节点；客户端将请求发送给选中的节点，然后\n\nmemcached节点通过一个内部的哈希算法（阶段二哈希），查找真正的数据（item）并返回给客户端。从实现的角度看，memcached是一个非阻塞的、基于事件的服务器程序。\n\n8、memcached最大的优势是什么？\n\nMemcached最大的好处就是它带来了极佳的水平可扩展性，特别是在一个巨大的系统中。由于客户端自己做了一次哈希，那么我们很容易增加大量memcached到集群中。memcached\n\n之间没有相互通信，因此不会增加 memcached的负载；没有多播协议，不会网络通信量爆炸（implode）。\n\n9、memcached和MySQL的query cache相比，有什么优缺点？\n\n缺点：\n\n1）相比MySQL的query cache，把memcached引入应用中需要不少的工作量。MySQL的query cache，可以自动地缓存SQL查询的结果，被缓存的SQL查询可以被反复、快速的执行。\n\n优点：\n\n1）当修改表时，MySQL的query cache会立刻被刷新（flush）。当写操作很频繁时，MySQL的query cache会经常让所有缓存数据都失效。\n\n2）在多核CPU上，MySQL的query cache会遇到扩展问题（scalability issues）。在多核CPU上，query cache会增加一个全局锁（global lock）, 由于需要刷新更多的缓存数据，速度\n\n会变得更慢。\n\n3）在MySQL的query cache中，是不能存储任意的数据的（只能是SQL查询结果）。利用memcached，我们可以搭建出各种高效的缓存。比如，可以执行多个独立的查询，构建出一个\n\n用户对象（user object），然后将用户对象缓存到memcached中。而query cache是SQL语句级别的，不可能做到这一点。在小的网站中，query cache会有所帮助，但随着网站规模的\n\n增加，query cache的弊将大于利。\n\n4）query cache能够利用的内存容量受到MySQL服务器空闲内存空间的限制。给数据库服务器增加更多的内存来缓存数据，固然是很好的。但是，有了memcached，只要您有空闲的内\n\n存，都可以用来增加memcached集群的规模，然后您就可以缓存更多的数据。\n\n10、memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？\n\n1）首先，local cache面临着严重的内存限制，能够利用的内存容量受到（单台）服务器空闲内存空间的限制。\n\n2）local cache有一点比memcached和query cache都要好，那就是它不但可以存储任意的数据，而且没有网络存取的延迟。因此，local cache的数据查询更快。考虑把highly\n\ncommon的数据放在local cache中吧。如果每个页面都需要加载一些数量较少的数据，可以考虑把它们放在local cached。\n\n3）local cache缺少集体失效（group invalidation）的特性。在memcached集群中，删除或更新一个key会让所有的观察者觉察到。但是在local cache中, 我们只能通知所有的服务器\n\n刷新cache（很慢，不具扩展性）或者仅仅依赖缓存超时失效机制。\n\n11、memcached的cache机制是怎样的？\n\nMemcached主要的cache机制是LRU（最近最少用）算法+超时失效。当您存数据到memcached中，可以指定该数据在缓存中可以呆多久Which is forever, or some time in the\n\nfuture。如果memcached的内存不够用了，过期的slabs会优先被替换，接着就轮到最老的未被使用的slabs。\n\n12、memcached如何实现冗余机制？\n\n不实现！Memcached应该是应用的缓存层，从设计本身来京就不带有任何冗余机制。如果一个memcached节点失去了所有数据，应该可以从数据源（比如数据库）再次获取到数据。应\n\n用系统应该可以容忍节点的失效。如果担心节点失效会大大加重数据库的负担，那么可以采取一些办法。比如您可以增加更多的节点（来减少丢失一个节点的影响），热备节点（在其他节\n\n点down了的时候接管IP）等等。\n\n13、memcached如何处理容错的？\n\n在节点失效的情况下，集群没有必要做任何容错处理。如果发生了节点失效，应对的措施完全取决于用户。\n\n节点失效时，下面列出几种方案供您选择：\n\n1）忽略它！ 在失效节点被恢复或替换之前，还有很多其他节点可以应对节点失效带来的影响。\n\n2）把失效的节点从节点列表中移除。做这个操作千万要小心！在默认情况下（余数式哈希算法），客户端添加或移除节点，会导致所有的缓存数据不可用！因为哈希参照的节点列表变化\n\n了，大部分key会因为哈希值的改变而被映射到（与原来）不同的节点上。\n\n3）启动热备节点，接管失效节点所占用的IP。这样可以防止哈希紊乱（hashing chaos）。\n\n4）如果希望添加和移除节点，而不影响原先的哈希结果，可以使用一致性哈希算法（consistent hashing）。\n\n5）两次哈希（reshing）。当客户端存取数据时，如果发现一个节点down了，就再做一次哈希（哈希算法与前一次不同），重新选择另一个节点（需要注意的时，客户端并没有把down\n\n的节点从节点列表中移除，下次还是有可能先哈希到它）。如果某个节点时好时坏，两次哈希的方法就有风险了，好的节点和坏的节点上都可能存在脏数据（stale data）。\n\n14、如何将memcached中item批量导入导出？\n\n不应该这样做！Memcached是一个非阻塞的服务器。任何可能导致memcached暂停或瞬时拒绝服务的操作都应该值得深思熟虑。向memcached中批量导入数据往往不是您真正想要\n\n的！想象看，如果缓存数据在导出导入之间发生了变化，您就需要处理脏数据了；如果缓存数据在导出导入之间过期了，您又怎么处理这些数据呢？\n\n因此，批量导出导入数据并不像想象中的那么有用。不过在一个场景倒是很有用。如果您有大量的从不变化 的数据，并且希望缓存很快热（warm）起来，批量导入缓存数据是很有帮助\n\n的。\n\n15、但是我确实需要把memcached中的item批量导出导入，怎么办？？\n\n如果需要批量导出和导入，最可能的原因一般是重新生成缓存数据需要消耗很长的时间或者数据库坏了让您饱受痛苦。\n\n如果一个memcached节点down了让您很痛苦，那么必须对数据库做一些优化工作。比如处理\"惊群\"问题（ memcached节点都失效了，反复的查询让数据库不堪重负）或者存在优化不\n\n好的查询等。Memcached 并不是逃避优化查询的借口和方案。\n\n这里给出一些提示：\n\n使用MogileFS（或者CouchDB等类似的软件）在存储item，把item计算出来并dump到磁盘上。MogileFS可以很方便地覆写item，并提供快速地访问。甚至可以把MogileFS中的item\n\n缓存在memcached中，这样可以加快读取速度。 MogileFS+Memcached的组合可以加快缓存不命中时的响应速度，提高网站的可用性。\n\n重新使用MySQL。MySQL的 InnoDB主键查询速度非常快。如果大部分缓存数据都可以放到VARCHAR字段中，那么主键查询的性能将更好。从memcached中按key查询几乎等价于\n\nMySQL的主键查询：将key 哈希到64-bit的整数，然后将数据存储到MySQL中。您可以把原始（不做哈希）的key存储都普通的字段中，然后建立二级索引来加快查询...key被动地失效，\n\n批量删除失效的key，等等。\n\n16、memcached是如何做身份验证的？\n\n没有身份认证机制！memcached是运行在应用下层的软件（身份验证应该是应用上层的职责）。memcached的客户端和服务器端之所以是轻量级的，部分原因就是完全没有实现身份验\n\n证机制。这样，memcached可以很快地创建新连接，服务器端也无需任何配置。如果您希望限制访问，您可以使用防火墙，或者让memcached监听unix domain socket。\n\n17、memcached的多线程是什么？如何使用它们？\n\n线程就是定律（threads rule）！在Steven Grimm和Facebook的努力下，memcached 1.2及更高版本拥有了多线程模式。多线程模式允许memcached能够充分利用多个CPU，并在\n\nCPU之间共享所有的缓存数据。memcached使用一种简单的锁机制来保证数据更新操作的互斥。相比在同一个物理机器上运行多个memcached实例，这种方式能够更有效地处理multi\n\ngets。如果系统的负载并不重，那么不需要启用多线程工作模式。如果您在运行一个拥有大规模硬件的、庞大的网站，将体验到看到多线程的好处。更多信息请参见：\n\nhttp://code.sixapart.com/svn/memcached/trunk/server/doc/threads.txt 。\n\n简单地总结一下：命令解析（memcached在这里花了大部分时间）可以运行在多线程模式下。memcached内部对数据的操作是基于很多全局锁的（因此这部分工作不是多线程的）。未\n\n来对多线程模式的改进，将移除大量的全局锁，提高memcached在负载极高的场景下的性能。\n\n18、memcached能接受的key的最大长度是多少？\n\nmemcached能接受的key的最大长度是250个字符。需要注意的是，250是memcached服务器端内部的限制。如果使用的Memcached客户端支持\"key的前缀\"或类似特性，那么key\n\n（前缀+原始key）的最大长度是可以超过250个字符的。推荐使用较短的key，这样可以节省内存和带宽。\n\n19、memcached对item的过期时间有什么限制？\n\nitem对象的过期时间最长可以达到30天。memcached把传入的过期时间（时间段）解释成时间点后，一旦到了这个时间点，memcached就把item置为失效状态，这是一个简单但\n\nobscure的机制。\n\n20、memcached最大能存储多大的单个item？\n\nmemcached最大能存储1MB的单个item。如果需要被缓存的数据大于1MB，可以考虑在客户端压缩或拆分到多个key中。\n\n21、为什么单个item的大小被限制在1M byte之内？\n\n简单的回答：因为内存分配器的算法就是这样的。\n\n详细的回答：\n\n1）Memcached的内存存储引擎，使用slabs来管理内存。内存被分成大小不等的slabs chunks（先分成大小相等的slabs，然后每个slab被分成大小相等chunks，不同slab的chunk大小\n\n是不相等的）。chunk的大小依次从一个最小数开始，按某个因子增长，直到达到最大的可能值。如果最小值为400B，最大值是1MB，因子是1.20，各个slab的chunk的大小依次是：\n\nslab1 - 400B；slab2 - 480B；slab3 - 576B ...slab中chunk越大，它和前面的slab之间的间隙就越大。因此，最大值越大，内存利用率越低。Memcached必须为每个slab预先分配内\n\n存，因此如果设置了较小的因子和较大的最大值，会需要为Memcached提供更多的内存。\n\n2）不要尝试向memcached中存取很大的数据，例如把巨大的网页放到mencached中。因为将大数据load和unpack到内存中需要花费很长的时间，从而导致系统的性能反而不好。如果\n\n确实需要存储大于1MB的数据，可以修改slabs.c：POWER_BLOCK的值，然后重新编译memcached；或者使用低效的malloc/free。另外，可以使用数据库、MogileFS等方案代替\n\nMemcached系统。\n\n22、可以在不同的memcached节点上使用大小不等的缓存空间吗？如果这么做之后，memcached能够更有效地使用内存吗？\n\nMemcache客户端仅根据哈希算法来决定将某个key存储在哪个节点上，而不考虑节点的内存大小。因此，可以在不同的节点上使用大小不等的内存作为缓存空间。但是一般可以这样做\n\n：拥有较多内存的节点上可以运行多个memcached实例，每个实例使用的内存跟其他节点上的实例相同。\n\n23、什么是二进制协议，是否需要关注？\n\n二进制协议尝试为端提供一个更有效的、可靠的协议，减少客户端/服务器端因处理协议而产生的CPU时间。根据Facebook的测试，解析ASCII协议是memcached中消耗CPU时间最多的\n\n环节。\n\n24、memcached的内存分配器是如何工作的？为什么不适用malloc/free！？为何要使用slabs？\n\n实际上，这是一个编译时选项。默认会使用内部的slab分配器，而且确实应该使用内建的slab分配器。最早的时候，memcached只使用malloc/free来管理内存。然而，这种方式不能与\n\nOS的内存管理以前很好地工作。反复地malloc/free造成了内存碎片，OS最终花费大量的时间去查找连续的内存块来满足malloc的请求，而不是运行memcached进程。slab分配器就是\n\n为了解决这个问题而生的。内存被分配并划分成chunks，一直被重复使用。因为内存被划分成大小不等的slabs，如果item的大小与被选择存放它的slab不是很合适的话，就会浪费一些内存。\n\n25、memcached是原子的吗？\n\n所有的被发送到memcached的单个命令是完全原子的。如果您针对同一份数据同时发送了一个set命令和一个get命令，它们不会影响对方。它们将被串行化、先后执行。即使在多线程模\n\n式，所有的命令都是原子的。然是，命令序列不是原子的。如果首先通过get命令获取了一个item，修改了它，然后再把它set回memcached，系统不保证这个item没有被其他进程\n\n（process，未必是操作系统中的进程）操作过。memcached 1.2.5以及更高版本，提供了gets和cas命令，它们可以解决上面的问题。如果使用gets命令查询某个key的item，\n\nmemcached会返回该item当前值的唯一标识。如果客户端程序覆写了这个item并想把它写回到memcached中，可以通过cas命令把那个唯一标识一起发送给memcached。如果该item\n\n存放在memcached中的唯一标识与您提供的一致，写操作将会成功。如果另一个进程在这期间也修改了这个item，那么该item存放在memcached中的唯一标识将会改变，写操作就会\n\n失败。\n\n性能和客户端库方面的问题\n\n26、memcached没有我的database快，为什么？\n\n在一对一比较中，memcached可能没有SQL查询快。但是，这不是memcached的设计目标。Memcached的目标是可伸缩性。当连接和请求增加的时候，memcached的性能将比\n\n大多数数据库查询好。可以先在高负载的环境（并发的连接和请求）中测试您的代码，然后再决定memcached是否适合您。\n\n27、使用不同的客户端库，可以访问到memcached中相同的数据吗？\n\n从技术上说，是可以的。但是可能会遇到下面三个问题：\n\n1）不同的库采用不同的方式序列化数据。举个例子，perl的Cache::Memcached使用Storable来序列化结构复杂的数据（比如hash references, objects, 等）。其他语言的客户端库很\n\n可能不能读取这种格式的数据。如果您要存储复杂的数据并且想被多种客户端库读取，那么您应该以简单的string格式来存储，并且这种格式可以被JSON、XML等外部库解析。\n\n2）从某个客户端来的数据被压缩了，从另一个客户端来的却没被压缩。\n\n3）各个客户端库可能使用不同的哈希算法（阶段一哈希）。在连接到多个memcached服务器端的情况下，客户端库根据自身实现的哈希算法把key映射到某台memcached上。正是因为\n\n不同的客户端库使用不同的哈希算法，所以被Perl客户端库映射到memcached A的key，可能又会被Python客户端库映射到memcached B，等等。Perl客户端库还允许为每台\n\nmemcached指定不同的权重（weight），这也是导致这个问题的一个因素。\n\n28、什么是一致性哈希的客户端？\n\n这里有一篇文章很好地解释了它的用处：http://www.last.fm/user/RJ/journal/2007/04/10/392555 。\n\n客户端可以通过\"前缀\"来给key设置一个域（命名空间）。例如，在一个共享主机的环境中，可以将客户姓名作为\"前缀\"，为key创建一个特定的域。在存储数据的时候，\"前缀\"可以用在\n\nkey上，但是不应该参与哈希计算。目前，memcached自己还没有实现针对复杂结构数据的序列化方法，JSON则是一种被广泛使用的对象序列化格式。\n\n哈希 / 键分布\n\n29、什么时候失效的数据项会从缓存中删除？\n\nmemcached 使用懒失效，当客户端请求数据项时， memcached 在返回数据前会检查失效时间来确定数据项是否已经失效。同样地，当添加一个新的数据项时，如果缓存已经满了， memcached 就会先替换失效的数据项，然后才是缓存中最少使用的数据项。\n\n命名空间\n\n30、memcached 不支持命名空间。以下提供几种模仿命名空间的方式：\n\n1）用键的前缀模仿命名空间：在真实的键之前加入有意义的前缀。\n\n2）用命名空间删除数据项：尽管 memcached 不支持使用任何类型的通配符或命名空间来完成删除操作，但是可以采用一些技巧来替代：\n\n在 PHP 中使用一个叫 foo 的命名空间：$ns_key = $memcache->get(\"foo_namespace_key\");\n\n// if not set, initialize it\n\nif($ns_key=false) $memcache->set(\"foo_namespace_key\", rand(1, 10000));\n\n$my_key = \"foo_\".$ns_key.\"_12345\";\n\n清除命名空间：$memcache->increment(\"foo_namespace_key\");\n\n应用设计\n\n31、在设计应用时，可以通过Memcached缓存那些内容？\n\n1）缓存简单的查询结果：查询缓存存储了给定查询语句对应的整个结果集，最合适缓存那些经常被用到，但不会改变的 SQL 语句对查询到的结果集，比如载入特定的过滤内容。\n\n$key = md5('SELECT * FROM rest_of_sql_statement_goes_here');\n\nif ($memcache->get($key)) {\n\n      ` return $memcache->get($key);`\n\n}else {\n\n    ` // Run the query and transform the result data into your final dataset form`\n\n    ` $result = $query_results_mangled_into_most_likely_an_array`\n\n     ` $memcache->set($key, $result, TRUE, 86400); // Store the result of the query for a day`\n\n    ` return $result;`\n\n}\n\n记住，如果查询语句对应的结果集改变，该结果集不会展现出来。这种方法不总是有用，但它确实让工作变得比较快。\n\n2）缓存简单的基于行的查询结果：基于行的缓存会检查缓存数据key的列表，那些在缓存中的行可以直接被取出，不在缓存中的行将会从数据库中取出并以唯一的键为标识缓存起来，最\n\n后加入到最终的数据集中返回。随着时间的推移，大多数数据都会被缓存，这也意味着相比与数据库，查询语句会更多地从 memcached 中得到数据行。如果数据是相当静态的，我们可\n\n以设置一个较长的缓存时间。\n\n基于行的缓存模式对下面这种搜索情况特别有用：数据集本身很大或是数据集是从多张表中得到，而数据集取决于查询的输入参数但是查询的结果集之间的有重复部分。\n\n比如，如果你有用户 A ， B ， C ， D ， E 的数据集。你去点击一张显示用户 A ， B ， E 信息的页面。首先， memcached 得到 3 个不同的键，每个对应一个用户去缓存中查找，全部未\n\n命中。然后就到数据库中用 SQL 查询得到 3 个用户的数据行，并缓存他们。\n\n现在，你又去点击另一张显示显示 C ， D ， E 信息的页面。当你去查找 memcached 时， C ， D 的数据并没有被命中，但我们命中了 E 的数据。然后从数据库得到 C ， D 的行数据，缓\n\n存在 memcached 中。至此以后，无论这些用户信息怎样地排列组合，任何关于 A ， B ， C ， D ， E 信息的页面都可以从 memcached 得到数据了。\n\n3）缓存的不只是 SQL 数据，可以缓存最终完成的部分显示页面，以节省CPU计算时间\n\n例如正在制作一张显示用户信息的页面，你可能得到一段关于用户的信息（姓名，生日，家庭住址，简介），然后你可能会将 XML 格式的简介信息转化为 HTML 格式或做其他的一些工\n\n作。相比单独存储这些属性，你可能更愿意存储经过渲染的数据块。那时你就可以简单地取出被预处理后的 HTML 直接填充在页面中，这样节省了宝贵的 CPU 时间。\n\n32、使用分层的缓存\n\nmemcached 可以高速处理大量的缓存数据，但是还是要根据系统的情况考虑维护多层的缓存结构。例如除了memcached缓存之外，还可以通过本地缓存（如ehcache、oscache等）建\n\n立起多级缓存。例如，可以采用本地缓存缓存一些基本数据，例如少量但访问频繁的数据（如产品分类，连接信息，服务器状态变量，应用配置变量等），缓存这些数据并让他们尽可能的\n\n接近处理器是有意义的 , 这样可以帮助减少生成页面的时间，并且在 memcached 失效的情况下可以增加可靠性。\n\n33、当数据更新时需要更新缓存\n\n用户编辑了自己的信息，当保存信息到数据库时，需要更新缓存中的数据或是简单地删除老的数据。如果马上更新数据，要防止从数据库读取那些刚刚更新过的数据。当用户习惯性地重新\n\n载入自己的用户信息来确认是否修改成功时，数据将从缓存中直接取出，这时他们获得了最新的数据。\n\n34、模拟带锁的添加命令\n\n如果你实在需要锁，你可以通过“添加”命令模仿锁的功能。尽管在未命中的情况下它不是那么有用，但如果你用它缓存平常的数据（应用服务器池的元数据）那还是有用的。\n\n比如，你要更新键 A 。\n\n1. 添加一个 \"lock:A\" 的键，这个键有一个持续几秒的过期时间（足够长以使你能完成计算和更新，也不要很长，因为如果锁进程挂了，这个键不会立即释放）\n\n2. 如果添加操作成功了，你就拥有了锁：从缓存获取键 A 的数据；利用客户端程序更改数据；更新缓存键 A 的数据；删除键 \"lock:A\" 。如果你不需要立即再次更新，就让它存活直到失效。\n\n3. 如果添加操作失败，说明有人获取了锁。这时让应用做些合适的事，比如返回老数据，等待后重试，或是其他的。\n\n以上这些操作类似 MySQL 将 GET_LOCK 的 timeout 值设置成 0 。没有办法在 memcached 中通过互斥锁模拟 GET_LOCK() 的 timeout 操作。\n\n35、预热你的缓存\n\n如果你有一个很高访问率的站点，并且你正想加入故障恢复功能或是其他全新的功能，你最终可能会碰到空缓存的问题。一开始缓存是空的，然后一大群人点击你的站点，在填充缓存的过\n\n程中，你的数据库可能会承受不住压力。为了解决这一问题，你可以试试任何可行的方法来 \" 温暖 \" 你的Memcached。方法：可以写一些脚本来缓存通用的页面；也可以写一个命令行工\n\n具来填充缓存。你可以在高峰时刻在缓存里填充一些内容。\n\n","slug":"Memcache-最佳实践","published":1,"updated":"2016-03-15T08:39:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cilt9a4sr0000rxzjqheduxzq","content":"<p>1、memcached的基本设置<br> 1）启动Memcache的服务器端 </p>\n<h1 id=\"usr-local-bin-memcached-d-m-10-u-root-l-192-168-0-200-p-12000-c-256-P-tmp-memcached-pid\"><a href=\"#usr-local-bin-memcached-d-m-10-u-root-l-192-168-0-200-p-12000-c-256-P-tmp-memcached-pid\" class=\"headerlink\" title=\"/usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid\"></a>/usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid</h1><p>-d选项是启动一个守护进程，<br>-m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，<br>-u是运行Memcache的用户，我这里是root，<br>-l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，<br>-p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，<br>-c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，<br>-P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，</p>\n<p> 2）如果要结束Memcache进程，执行：</p>\n<h1 id=\"kill-cat-tmp-memcached-pid\"><a href=\"#kill-cat-tmp-memcached-pid\" class=\"headerlink\" title=\"kill cat /tmp/memcached.pid\"></a>kill <code>cat /tmp/memcached.pid</code></h1><p>哈希算法将任意长度的二进制值映射为固定长度的较小二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。如果散列一段明文而且哪怕只更改该</p>\n<p>段落的一个字母，随后的哈希都将产生不同的值。要找到散列为同一个值的两个不同的输入，在计算上是不可能的。</p>\n<p>2、一致性Hash算法的目的有两点：一是节点变动后其他节点受影响尽可能小；二是节点变动后数据重新分配尽可能均衡 。</p>\n<p>3、为什么要运行 memcached ？</p>\n<p>如果网站的高流量很大并且大多数的访问会造成数据库高负荷的状况下，使用 memcached 能够减轻数据库的压力。</p>\n<p>4、适用memcached的业务场景？</p>\n<p>1）如果网站包含了访问量很大的动态网页，因而数据库的负载将会很高。由于大部分数据库请求都是读操作，那么memcached可以显著地减小数据库负载。</p>\n<p>2）如果数据库服务器的负载比较低但CPU使用率很高，这时可以缓存计算好的结果（ computed objects ）和渲染后的网页模板（enderred templates）。</p>\n<p>3）利用memcached可以缓存session数据、临时数据以减少对他们的数据库写操作。</p>\n<p>4）缓存一些很小但是被频繁访问的文件。</p>\n<p>5）缓存Web ‘services’（非IBM宣扬的Web Services，译者注）或RSS feeds的结果.。</p>\n<p>5、不适用memcached的业务场景？</p>\n<p>1）缓存对象的大小大于1MB</p>\n<p>Memcached本身就不是为了处理庞大的多媒体（large media）和巨大的二进制块（streaming huge blobs）而设计的。</p>\n<p>2）key的长度大于250字符</p>\n<p>3）虚拟主机不让运行memcached服务</p>\n<pre><code>如果应用本身托管在低端的虚拟私有服务器上，像vmware, xen这类虚拟化技术并不适合运行memcached。Memcached需要接管和控制大块的内存，如果memcached管理的内存\n</code></pre><p>被OS或 hypervisor交换出去，memcached的性能将大打折扣。</p>\n<p>4）应用运行在不安全的环境中</p>\n<p>Memcached为提供任何安全策略，仅仅通过telnet就可以访问到memcached。如果应用运行在共享的系统上，需要着重考虑安全问题。</p>\n<p>5）业务本身需要的是持久化数据或者说需要的应该是database</p>\n<p>6、能够遍历memcached中所有的item吗？</p>\n<p>不能，这个操作的速度相对缓慢且阻塞其他的操作（这里的缓慢时相比memcached其他的命令）。memcached所有非调试（non-debug）命令，例如add, set, get, fulsh等无论</p>\n<p>memcached中存储了多少数据，它们的执行都只消耗常量时间。任何遍历所有item的命令执行所消耗的时间，将随着memcached中数据量的增加而增加。当其他命令因为等待（遍历所</p>\n<p>有item的命令执行完毕）而不能得到执行，因而阻塞将发生。</p>\n<p>集群的相关问题</p>\n<p>7、memcached是怎么工作的？</p>\n<p>Memcached的高性能源于两阶段哈希（two-stage hash）结构。Memcached就像一个巨大的、存储了很多<key,value>对的哈希表。通过key，可以存储或查询任意的数据。 客户端</key,value></p>\n<p>可以把数据存储在多台memcached上。当查询数据时，客户端首先参考节点列表计算出key的哈希值（阶段一哈希），进而选中一个节点；客户端将请求发送给选中的节点，然后</p>\n<p>memcached节点通过一个内部的哈希算法（阶段二哈希），查找真正的数据（item）并返回给客户端。从实现的角度看，memcached是一个非阻塞的、基于事件的服务器程序。</p>\n<p>8、memcached最大的优势是什么？</p>\n<p>Memcached最大的好处就是它带来了极佳的水平可扩展性，特别是在一个巨大的系统中。由于客户端自己做了一次哈希，那么我们很容易增加大量memcached到集群中。memcached</p>\n<p>之间没有相互通信，因此不会增加 memcached的负载；没有多播协议，不会网络通信量爆炸（implode）。</p>\n<p>9、memcached和MySQL的query cache相比，有什么优缺点？</p>\n<p>缺点：</p>\n<p>1）相比MySQL的query cache，把memcached引入应用中需要不少的工作量。MySQL的query cache，可以自动地缓存SQL查询的结果，被缓存的SQL查询可以被反复、快速的执行。</p>\n<p>优点：</p>\n<p>1）当修改表时，MySQL的query cache会立刻被刷新（flush）。当写操作很频繁时，MySQL的query cache会经常让所有缓存数据都失效。</p>\n<p>2）在多核CPU上，MySQL的query cache会遇到扩展问题（scalability issues）。在多核CPU上，query cache会增加一个全局锁（global lock）, 由于需要刷新更多的缓存数据，速度</p>\n<p>会变得更慢。</p>\n<p>3）在MySQL的query cache中，是不能存储任意的数据的（只能是SQL查询结果）。利用memcached，我们可以搭建出各种高效的缓存。比如，可以执行多个独立的查询，构建出一个</p>\n<p>用户对象（user object），然后将用户对象缓存到memcached中。而query cache是SQL语句级别的，不可能做到这一点。在小的网站中，query cache会有所帮助，但随着网站规模的</p>\n<p>增加，query cache的弊将大于利。</p>\n<p>4）query cache能够利用的内存容量受到MySQL服务器空闲内存空间的限制。给数据库服务器增加更多的内存来缓存数据，固然是很好的。但是，有了memcached，只要您有空闲的内</p>\n<p>存，都可以用来增加memcached集群的规模，然后您就可以缓存更多的数据。</p>\n<p>10、memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？</p>\n<p>1）首先，local cache面临着严重的内存限制，能够利用的内存容量受到（单台）服务器空闲内存空间的限制。</p>\n<p>2）local cache有一点比memcached和query cache都要好，那就是它不但可以存储任意的数据，而且没有网络存取的延迟。因此，local cache的数据查询更快。考虑把highly</p>\n<p>common的数据放在local cache中吧。如果每个页面都需要加载一些数量较少的数据，可以考虑把它们放在local cached。</p>\n<p>3）local cache缺少集体失效（group invalidation）的特性。在memcached集群中，删除或更新一个key会让所有的观察者觉察到。但是在local cache中, 我们只能通知所有的服务器</p>\n<p>刷新cache（很慢，不具扩展性）或者仅仅依赖缓存超时失效机制。</p>\n<p>11、memcached的cache机制是怎样的？</p>\n<p>Memcached主要的cache机制是LRU（最近最少用）算法+超时失效。当您存数据到memcached中，可以指定该数据在缓存中可以呆多久Which is forever, or some time in the</p>\n<p>future。如果memcached的内存不够用了，过期的slabs会优先被替换，接着就轮到最老的未被使用的slabs。</p>\n<p>12、memcached如何实现冗余机制？</p>\n<p>不实现！Memcached应该是应用的缓存层，从设计本身来京就不带有任何冗余机制。如果一个memcached节点失去了所有数据，应该可以从数据源（比如数据库）再次获取到数据。应</p>\n<p>用系统应该可以容忍节点的失效。如果担心节点失效会大大加重数据库的负担，那么可以采取一些办法。比如您可以增加更多的节点（来减少丢失一个节点的影响），热备节点（在其他节</p>\n<p>点down了的时候接管IP）等等。</p>\n<p>13、memcached如何处理容错的？</p>\n<p>在节点失效的情况下，集群没有必要做任何容错处理。如果发生了节点失效，应对的措施完全取决于用户。</p>\n<p>节点失效时，下面列出几种方案供您选择：</p>\n<p>1）忽略它！ 在失效节点被恢复或替换之前，还有很多其他节点可以应对节点失效带来的影响。</p>\n<p>2）把失效的节点从节点列表中移除。做这个操作千万要小心！在默认情况下（余数式哈希算法），客户端添加或移除节点，会导致所有的缓存数据不可用！因为哈希参照的节点列表变化</p>\n<p>了，大部分key会因为哈希值的改变而被映射到（与原来）不同的节点上。</p>\n<p>3）启动热备节点，接管失效节点所占用的IP。这样可以防止哈希紊乱（hashing chaos）。</p>\n<p>4）如果希望添加和移除节点，而不影响原先的哈希结果，可以使用一致性哈希算法（consistent hashing）。</p>\n<p>5）两次哈希（reshing）。当客户端存取数据时，如果发现一个节点down了，就再做一次哈希（哈希算法与前一次不同），重新选择另一个节点（需要注意的时，客户端并没有把down</p>\n<p>的节点从节点列表中移除，下次还是有可能先哈希到它）。如果某个节点时好时坏，两次哈希的方法就有风险了，好的节点和坏的节点上都可能存在脏数据（stale data）。</p>\n<p>14、如何将memcached中item批量导入导出？</p>\n<p>不应该这样做！Memcached是一个非阻塞的服务器。任何可能导致memcached暂停或瞬时拒绝服务的操作都应该值得深思熟虑。向memcached中批量导入数据往往不是您真正想要</p>\n<p>的！想象看，如果缓存数据在导出导入之间发生了变化，您就需要处理脏数据了；如果缓存数据在导出导入之间过期了，您又怎么处理这些数据呢？</p>\n<p>因此，批量导出导入数据并不像想象中的那么有用。不过在一个场景倒是很有用。如果您有大量的从不变化 的数据，并且希望缓存很快热（warm）起来，批量导入缓存数据是很有帮助</p>\n<p>的。</p>\n<p>15、但是我确实需要把memcached中的item批量导出导入，怎么办？？</p>\n<p>如果需要批量导出和导入，最可能的原因一般是重新生成缓存数据需要消耗很长的时间或者数据库坏了让您饱受痛苦。</p>\n<p>如果一个memcached节点down了让您很痛苦，那么必须对数据库做一些优化工作。比如处理”惊群”问题（ memcached节点都失效了，反复的查询让数据库不堪重负）或者存在优化不</p>\n<p>好的查询等。Memcached 并不是逃避优化查询的借口和方案。</p>\n<p>这里给出一些提示：</p>\n<p>使用MogileFS（或者CouchDB等类似的软件）在存储item，把item计算出来并dump到磁盘上。MogileFS可以很方便地覆写item，并提供快速地访问。甚至可以把MogileFS中的item</p>\n<p>缓存在memcached中，这样可以加快读取速度。 MogileFS+Memcached的组合可以加快缓存不命中时的响应速度，提高网站的可用性。</p>\n<p>重新使用MySQL。MySQL的 InnoDB主键查询速度非常快。如果大部分缓存数据都可以放到VARCHAR字段中，那么主键查询的性能将更好。从memcached中按key查询几乎等价于</p>\n<p>MySQL的主键查询：将key 哈希到64-bit的整数，然后将数据存储到MySQL中。您可以把原始（不做哈希）的key存储都普通的字段中，然后建立二级索引来加快查询…key被动地失效，</p>\n<p>批量删除失效的key，等等。</p>\n<p>16、memcached是如何做身份验证的？</p>\n<p>没有身份认证机制！memcached是运行在应用下层的软件（身份验证应该是应用上层的职责）。memcached的客户端和服务器端之所以是轻量级的，部分原因就是完全没有实现身份验</p>\n<p>证机制。这样，memcached可以很快地创建新连接，服务器端也无需任何配置。如果您希望限制访问，您可以使用防火墙，或者让memcached监听unix domain socket。</p>\n<p>17、memcached的多线程是什么？如何使用它们？</p>\n<p>线程就是定律（threads rule）！在Steven Grimm和Facebook的努力下，memcached 1.2及更高版本拥有了多线程模式。多线程模式允许memcached能够充分利用多个CPU，并在</p>\n<p>CPU之间共享所有的缓存数据。memcached使用一种简单的锁机制来保证数据更新操作的互斥。相比在同一个物理机器上运行多个memcached实例，这种方式能够更有效地处理multi</p>\n<p>gets。如果系统的负载并不重，那么不需要启用多线程工作模式。如果您在运行一个拥有大规模硬件的、庞大的网站，将体验到看到多线程的好处。更多信息请参见：</p>\n<p><a href=\"http://code.sixapart.com/svn/memcached/trunk/server/doc/threads.txt\" target=\"_blank\" rel=\"external\">http://code.sixapart.com/svn/memcached/trunk/server/doc/threads.txt</a> 。</p>\n<p>简单地总结一下：命令解析（memcached在这里花了大部分时间）可以运行在多线程模式下。memcached内部对数据的操作是基于很多全局锁的（因此这部分工作不是多线程的）。未</p>\n<p>来对多线程模式的改进，将移除大量的全局锁，提高memcached在负载极高的场景下的性能。</p>\n<p>18、memcached能接受的key的最大长度是多少？</p>\n<p>memcached能接受的key的最大长度是250个字符。需要注意的是，250是memcached服务器端内部的限制。如果使用的Memcached客户端支持”key的前缀”或类似特性，那么key</p>\n<p>（前缀+原始key）的最大长度是可以超过250个字符的。推荐使用较短的key，这样可以节省内存和带宽。</p>\n<p>19、memcached对item的过期时间有什么限制？</p>\n<p>item对象的过期时间最长可以达到30天。memcached把传入的过期时间（时间段）解释成时间点后，一旦到了这个时间点，memcached就把item置为失效状态，这是一个简单但</p>\n<p>obscure的机制。</p>\n<p>20、memcached最大能存储多大的单个item？</p>\n<p>memcached最大能存储1MB的单个item。如果需要被缓存的数据大于1MB，可以考虑在客户端压缩或拆分到多个key中。</p>\n<p>21、为什么单个item的大小被限制在1M byte之内？</p>\n<p>简单的回答：因为内存分配器的算法就是这样的。</p>\n<p>详细的回答：</p>\n<p>1）Memcached的内存存储引擎，使用slabs来管理内存。内存被分成大小不等的slabs chunks（先分成大小相等的slabs，然后每个slab被分成大小相等chunks，不同slab的chunk大小</p>\n<p>是不相等的）。chunk的大小依次从一个最小数开始，按某个因子增长，直到达到最大的可能值。如果最小值为400B，最大值是1MB，因子是1.20，各个slab的chunk的大小依次是：</p>\n<p>slab1 - 400B；slab2 - 480B；slab3 - 576B …slab中chunk越大，它和前面的slab之间的间隙就越大。因此，最大值越大，内存利用率越低。Memcached必须为每个slab预先分配内</p>\n<p>存，因此如果设置了较小的因子和较大的最大值，会需要为Memcached提供更多的内存。</p>\n<p>2）不要尝试向memcached中存取很大的数据，例如把巨大的网页放到mencached中。因为将大数据load和unpack到内存中需要花费很长的时间，从而导致系统的性能反而不好。如果</p>\n<p>确实需要存储大于1MB的数据，可以修改slabs.c：POWER_BLOCK的值，然后重新编译memcached；或者使用低效的malloc/free。另外，可以使用数据库、MogileFS等方案代替</p>\n<p>Memcached系统。</p>\n<p>22、可以在不同的memcached节点上使用大小不等的缓存空间吗？如果这么做之后，memcached能够更有效地使用内存吗？</p>\n<p>Memcache客户端仅根据哈希算法来决定将某个key存储在哪个节点上，而不考虑节点的内存大小。因此，可以在不同的节点上使用大小不等的内存作为缓存空间。但是一般可以这样做</p>\n<p>：拥有较多内存的节点上可以运行多个memcached实例，每个实例使用的内存跟其他节点上的实例相同。</p>\n<p>23、什么是二进制协议，是否需要关注？</p>\n<p>二进制协议尝试为端提供一个更有效的、可靠的协议，减少客户端/服务器端因处理协议而产生的CPU时间。根据Facebook的测试，解析ASCII协议是memcached中消耗CPU时间最多的</p>\n<p>环节。</p>\n<p>24、memcached的内存分配器是如何工作的？为什么不适用malloc/free！？为何要使用slabs？</p>\n<p>实际上，这是一个编译时选项。默认会使用内部的slab分配器，而且确实应该使用内建的slab分配器。最早的时候，memcached只使用malloc/free来管理内存。然而，这种方式不能与</p>\n<p>OS的内存管理以前很好地工作。反复地malloc/free造成了内存碎片，OS最终花费大量的时间去查找连续的内存块来满足malloc的请求，而不是运行memcached进程。slab分配器就是</p>\n<p>为了解决这个问题而生的。内存被分配并划分成chunks，一直被重复使用。因为内存被划分成大小不等的slabs，如果item的大小与被选择存放它的slab不是很合适的话，就会浪费一些内存。</p>\n<p>25、memcached是原子的吗？</p>\n<p>所有的被发送到memcached的单个命令是完全原子的。如果您针对同一份数据同时发送了一个set命令和一个get命令，它们不会影响对方。它们将被串行化、先后执行。即使在多线程模</p>\n<p>式，所有的命令都是原子的。然是，命令序列不是原子的。如果首先通过get命令获取了一个item，修改了它，然后再把它set回memcached，系统不保证这个item没有被其他进程</p>\n<p>（process，未必是操作系统中的进程）操作过。memcached 1.2.5以及更高版本，提供了gets和cas命令，它们可以解决上面的问题。如果使用gets命令查询某个key的item，</p>\n<p>memcached会返回该item当前值的唯一标识。如果客户端程序覆写了这个item并想把它写回到memcached中，可以通过cas命令把那个唯一标识一起发送给memcached。如果该item</p>\n<p>存放在memcached中的唯一标识与您提供的一致，写操作将会成功。如果另一个进程在这期间也修改了这个item，那么该item存放在memcached中的唯一标识将会改变，写操作就会</p>\n<p>失败。</p>\n<p>性能和客户端库方面的问题</p>\n<p>26、memcached没有我的database快，为什么？</p>\n<p>在一对一比较中，memcached可能没有SQL查询快。但是，这不是memcached的设计目标。Memcached的目标是可伸缩性。当连接和请求增加的时候，memcached的性能将比</p>\n<p>大多数数据库查询好。可以先在高负载的环境（并发的连接和请求）中测试您的代码，然后再决定memcached是否适合您。</p>\n<p>27、使用不同的客户端库，可以访问到memcached中相同的数据吗？</p>\n<p>从技术上说，是可以的。但是可能会遇到下面三个问题：</p>\n<p>1）不同的库采用不同的方式序列化数据。举个例子，perl的Cache::Memcached使用Storable来序列化结构复杂的数据（比如hash references, objects, 等）。其他语言的客户端库很</p>\n<p>可能不能读取这种格式的数据。如果您要存储复杂的数据并且想被多种客户端库读取，那么您应该以简单的string格式来存储，并且这种格式可以被JSON、XML等外部库解析。</p>\n<p>2）从某个客户端来的数据被压缩了，从另一个客户端来的却没被压缩。</p>\n<p>3）各个客户端库可能使用不同的哈希算法（阶段一哈希）。在连接到多个memcached服务器端的情况下，客户端库根据自身实现的哈希算法把key映射到某台memcached上。正是因为</p>\n<p>不同的客户端库使用不同的哈希算法，所以被Perl客户端库映射到memcached A的key，可能又会被Python客户端库映射到memcached B，等等。Perl客户端库还允许为每台</p>\n<p>memcached指定不同的权重（weight），这也是导致这个问题的一个因素。</p>\n<p>28、什么是一致性哈希的客户端？</p>\n<p>这里有一篇文章很好地解释了它的用处：<a href=\"http://www.last.fm/user/RJ/journal/2007/04/10/392555\" target=\"_blank\" rel=\"external\">http://www.last.fm/user/RJ/journal/2007/04/10/392555</a> 。</p>\n<p>客户端可以通过”前缀”来给key设置一个域（命名空间）。例如，在一个共享主机的环境中，可以将客户姓名作为”前缀”，为key创建一个特定的域。在存储数据的时候，”前缀”可以用在</p>\n<p>key上，但是不应该参与哈希计算。目前，memcached自己还没有实现针对复杂结构数据的序列化方法，JSON则是一种被广泛使用的对象序列化格式。</p>\n<p>哈希 / 键分布</p>\n<p>29、什么时候失效的数据项会从缓存中删除？</p>\n<p>memcached 使用懒失效，当客户端请求数据项时， memcached 在返回数据前会检查失效时间来确定数据项是否已经失效。同样地，当添加一个新的数据项时，如果缓存已经满了， memcached 就会先替换失效的数据项，然后才是缓存中最少使用的数据项。</p>\n<p>命名空间</p>\n<p>30、memcached 不支持命名空间。以下提供几种模仿命名空间的方式：</p>\n<p>1）用键的前缀模仿命名空间：在真实的键之前加入有意义的前缀。</p>\n<p>2）用命名空间删除数据项：尽管 memcached 不支持使用任何类型的通配符或命名空间来完成删除操作，但是可以采用一些技巧来替代：</p>\n<p>在 PHP 中使用一个叫 foo 的命名空间：$ns_key = $memcache-&gt;get(“foo_namespace_key”);</p>\n<p>// if not set, initialize it</p>\n<p>if($ns_key=false) $memcache-&gt;set(“foo_namespace_key”, rand(1, 10000));</p>\n<p>$my<em>key = “foo</em>“.$ns_key.”_12345”;</p>\n<p>清除命名空间：$memcache-&gt;increment(“foo_namespace_key”);</p>\n<p>应用设计</p>\n<p>31、在设计应用时，可以通过Memcached缓存那些内容？</p>\n<p>1）缓存简单的查询结果：查询缓存存储了给定查询语句对应的整个结果集，最合适缓存那些经常被用到，但不会改变的 SQL 语句对查询到的结果集，比如载入特定的过滤内容。</p>\n<p>$key = md5(‘SELECT * FROM rest_of_sql_statement_goes_here’);</p>\n<p>if ($memcache-&gt;get($key)) {</p>\n<pre><code>` return $memcache-&gt;get($key);`\n</code></pre><p>}else {</p>\n<pre><code>` // Run the query and transform the result data into your final dataset form`\n\n` $result = $query_results_mangled_into_most_likely_an_array`\n\n ` $memcache-&gt;set($key, $result, TRUE, 86400); // Store the result of the query for a day`\n\n` return $result;`\n</code></pre><p>}</p>\n<p>记住，如果查询语句对应的结果集改变，该结果集不会展现出来。这种方法不总是有用，但它确实让工作变得比较快。</p>\n<p>2）缓存简单的基于行的查询结果：基于行的缓存会检查缓存数据key的列表，那些在缓存中的行可以直接被取出，不在缓存中的行将会从数据库中取出并以唯一的键为标识缓存起来，最</p>\n<p>后加入到最终的数据集中返回。随着时间的推移，大多数数据都会被缓存，这也意味着相比与数据库，查询语句会更多地从 memcached 中得到数据行。如果数据是相当静态的，我们可</p>\n<p>以设置一个较长的缓存时间。</p>\n<p>基于行的缓存模式对下面这种搜索情况特别有用：数据集本身很大或是数据集是从多张表中得到，而数据集取决于查询的输入参数但是查询的结果集之间的有重复部分。</p>\n<p>比如，如果你有用户 A ， B ， C ， D ， E 的数据集。你去点击一张显示用户 A ， B ， E 信息的页面。首先， memcached 得到 3 个不同的键，每个对应一个用户去缓存中查找，全部未</p>\n<p>命中。然后就到数据库中用 SQL 查询得到 3 个用户的数据行，并缓存他们。</p>\n<p>现在，你又去点击另一张显示显示 C ， D ， E 信息的页面。当你去查找 memcached 时， C ， D 的数据并没有被命中，但我们命中了 E 的数据。然后从数据库得到 C ， D 的行数据，缓</p>\n<p>存在 memcached 中。至此以后，无论这些用户信息怎样地排列组合，任何关于 A ， B ， C ， D ， E 信息的页面都可以从 memcached 得到数据了。</p>\n<p>3）缓存的不只是 SQL 数据，可以缓存最终完成的部分显示页面，以节省CPU计算时间</p>\n<p>例如正在制作一张显示用户信息的页面，你可能得到一段关于用户的信息（姓名，生日，家庭住址，简介），然后你可能会将 XML 格式的简介信息转化为 HTML 格式或做其他的一些工</p>\n<p>作。相比单独存储这些属性，你可能更愿意存储经过渲染的数据块。那时你就可以简单地取出被预处理后的 HTML 直接填充在页面中，这样节省了宝贵的 CPU 时间。</p>\n<p>32、使用分层的缓存</p>\n<p>memcached 可以高速处理大量的缓存数据，但是还是要根据系统的情况考虑维护多层的缓存结构。例如除了memcached缓存之外，还可以通过本地缓存（如ehcache、oscache等）建</p>\n<p>立起多级缓存。例如，可以采用本地缓存缓存一些基本数据，例如少量但访问频繁的数据（如产品分类，连接信息，服务器状态变量，应用配置变量等），缓存这些数据并让他们尽可能的</p>\n<p>接近处理器是有意义的 , 这样可以帮助减少生成页面的时间，并且在 memcached 失效的情况下可以增加可靠性。</p>\n<p>33、当数据更新时需要更新缓存</p>\n<p>用户编辑了自己的信息，当保存信息到数据库时，需要更新缓存中的数据或是简单地删除老的数据。如果马上更新数据，要防止从数据库读取那些刚刚更新过的数据。当用户习惯性地重新</p>\n<p>载入自己的用户信息来确认是否修改成功时，数据将从缓存中直接取出，这时他们获得了最新的数据。</p>\n<p>34、模拟带锁的添加命令</p>\n<p>如果你实在需要锁，你可以通过“添加”命令模仿锁的功能。尽管在未命中的情况下它不是那么有用，但如果你用它缓存平常的数据（应用服务器池的元数据）那还是有用的。</p>\n<p>比如，你要更新键 A 。</p>\n<ol>\n<li><p>添加一个 “lock:A” 的键，这个键有一个持续几秒的过期时间（足够长以使你能完成计算和更新，也不要很长，因为如果锁进程挂了，这个键不会立即释放）</p>\n</li>\n<li><p>如果添加操作成功了，你就拥有了锁：从缓存获取键 A 的数据；利用客户端程序更改数据；更新缓存键 A 的数据；删除键 “lock:A” 。如果你不需要立即再次更新，就让它存活直到失效。</p>\n</li>\n<li><p>如果添加操作失败，说明有人获取了锁。这时让应用做些合适的事，比如返回老数据，等待后重试，或是其他的。</p>\n</li>\n</ol>\n<p>以上这些操作类似 MySQL 将 GET_LOCK 的 timeout 值设置成 0 。没有办法在 memcached 中通过互斥锁模拟 GET_LOCK() 的 timeout 操作。</p>\n<p>35、预热你的缓存</p>\n<p>如果你有一个很高访问率的站点，并且你正想加入故障恢复功能或是其他全新的功能，你最终可能会碰到空缓存的问题。一开始缓存是空的，然后一大群人点击你的站点，在填充缓存的过</p>\n<p>程中，你的数据库可能会承受不住压力。为了解决这一问题，你可以试试任何可行的方法来 “ 温暖 “ 你的Memcached。方法：可以写一些脚本来缓存通用的页面；也可以写一个命令行工</p>\n<p>具来填充缓存。你可以在高峰时刻在缓存里填充一些内容。</p>\n","excerpt":"","more":"<p>1、memcached的基本设置<br> 1）启动Memcache的服务器端 </p>\n<h1 id=\"usr-local-bin-memcached-d-m-10-u-root-l-192-168-0-200-p-12000-c-256-P-tmp-memcached-pid\"><a href=\"#usr-local-bin-memcached-d-m-10-u-root-l-192-168-0-200-p-12000-c-256-P-tmp-memcached-pid\" class=\"headerlink\" title=\"/usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid\"></a>/usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid</h1><p>-d选项是启动一个守护进程，<br>-m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，<br>-u是运行Memcache的用户，我这里是root，<br>-l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，<br>-p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，<br>-c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，<br>-P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，</p>\n<p> 2）如果要结束Memcache进程，执行：</p>\n<h1 id=\"kill-cat-tmp-memcached-pid\"><a href=\"#kill-cat-tmp-memcached-pid\" class=\"headerlink\" title=\"kill cat /tmp/memcached.pid\"></a>kill <code>cat /tmp/memcached.pid</code></h1><p>哈希算法将任意长度的二进制值映射为固定长度的较小二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。如果散列一段明文而且哪怕只更改该</p>\n<p>段落的一个字母，随后的哈希都将产生不同的值。要找到散列为同一个值的两个不同的输入，在计算上是不可能的。</p>\n<p>2、一致性Hash算法的目的有两点：一是节点变动后其他节点受影响尽可能小；二是节点变动后数据重新分配尽可能均衡 。</p>\n<p>3、为什么要运行 memcached ？</p>\n<p>如果网站的高流量很大并且大多数的访问会造成数据库高负荷的状况下，使用 memcached 能够减轻数据库的压力。</p>\n<p>4、适用memcached的业务场景？</p>\n<p>1）如果网站包含了访问量很大的动态网页，因而数据库的负载将会很高。由于大部分数据库请求都是读操作，那么memcached可以显著地减小数据库负载。</p>\n<p>2）如果数据库服务器的负载比较低但CPU使用率很高，这时可以缓存计算好的结果（ computed objects ）和渲染后的网页模板（enderred templates）。</p>\n<p>3）利用memcached可以缓存session数据、临时数据以减少对他们的数据库写操作。</p>\n<p>4）缓存一些很小但是被频繁访问的文件。</p>\n<p>5）缓存Web ‘services’（非IBM宣扬的Web Services，译者注）或RSS feeds的结果.。</p>\n<p>5、不适用memcached的业务场景？</p>\n<p>1）缓存对象的大小大于1MB</p>\n<p>Memcached本身就不是为了处理庞大的多媒体（large media）和巨大的二进制块（streaming huge blobs）而设计的。</p>\n<p>2）key的长度大于250字符</p>\n<p>3）虚拟主机不让运行memcached服务</p>\n<pre><code>如果应用本身托管在低端的虚拟私有服务器上，像vmware, xen这类虚拟化技术并不适合运行memcached。Memcached需要接管和控制大块的内存，如果memcached管理的内存\n</code></pre><p>被OS或 hypervisor交换出去，memcached的性能将大打折扣。</p>\n<p>4）应用运行在不安全的环境中</p>\n<p>Memcached为提供任何安全策略，仅仅通过telnet就可以访问到memcached。如果应用运行在共享的系统上，需要着重考虑安全问题。</p>\n<p>5）业务本身需要的是持久化数据或者说需要的应该是database</p>\n<p>6、能够遍历memcached中所有的item吗？</p>\n<p>不能，这个操作的速度相对缓慢且阻塞其他的操作（这里的缓慢时相比memcached其他的命令）。memcached所有非调试（non-debug）命令，例如add, set, get, fulsh等无论</p>\n<p>memcached中存储了多少数据，它们的执行都只消耗常量时间。任何遍历所有item的命令执行所消耗的时间，将随着memcached中数据量的增加而增加。当其他命令因为等待（遍历所</p>\n<p>有item的命令执行完毕）而不能得到执行，因而阻塞将发生。</p>\n<p>集群的相关问题</p>\n<p>7、memcached是怎么工作的？</p>\n<p>Memcached的高性能源于两阶段哈希（two-stage hash）结构。Memcached就像一个巨大的、存储了很多<key,value>对的哈希表。通过key，可以存储或查询任意的数据。 客户端</p>\n<p>可以把数据存储在多台memcached上。当查询数据时，客户端首先参考节点列表计算出key的哈希值（阶段一哈希），进而选中一个节点；客户端将请求发送给选中的节点，然后</p>\n<p>memcached节点通过一个内部的哈希算法（阶段二哈希），查找真正的数据（item）并返回给客户端。从实现的角度看，memcached是一个非阻塞的、基于事件的服务器程序。</p>\n<p>8、memcached最大的优势是什么？</p>\n<p>Memcached最大的好处就是它带来了极佳的水平可扩展性，特别是在一个巨大的系统中。由于客户端自己做了一次哈希，那么我们很容易增加大量memcached到集群中。memcached</p>\n<p>之间没有相互通信，因此不会增加 memcached的负载；没有多播协议，不会网络通信量爆炸（implode）。</p>\n<p>9、memcached和MySQL的query cache相比，有什么优缺点？</p>\n<p>缺点：</p>\n<p>1）相比MySQL的query cache，把memcached引入应用中需要不少的工作量。MySQL的query cache，可以自动地缓存SQL查询的结果，被缓存的SQL查询可以被反复、快速的执行。</p>\n<p>优点：</p>\n<p>1）当修改表时，MySQL的query cache会立刻被刷新（flush）。当写操作很频繁时，MySQL的query cache会经常让所有缓存数据都失效。</p>\n<p>2）在多核CPU上，MySQL的query cache会遇到扩展问题（scalability issues）。在多核CPU上，query cache会增加一个全局锁（global lock）, 由于需要刷新更多的缓存数据，速度</p>\n<p>会变得更慢。</p>\n<p>3）在MySQL的query cache中，是不能存储任意的数据的（只能是SQL查询结果）。利用memcached，我们可以搭建出各种高效的缓存。比如，可以执行多个独立的查询，构建出一个</p>\n<p>用户对象（user object），然后将用户对象缓存到memcached中。而query cache是SQL语句级别的，不可能做到这一点。在小的网站中，query cache会有所帮助，但随着网站规模的</p>\n<p>增加，query cache的弊将大于利。</p>\n<p>4）query cache能够利用的内存容量受到MySQL服务器空闲内存空间的限制。给数据库服务器增加更多的内存来缓存数据，固然是很好的。但是，有了memcached，只要您有空闲的内</p>\n<p>存，都可以用来增加memcached集群的规模，然后您就可以缓存更多的数据。</p>\n<p>10、memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？</p>\n<p>1）首先，local cache面临着严重的内存限制，能够利用的内存容量受到（单台）服务器空闲内存空间的限制。</p>\n<p>2）local cache有一点比memcached和query cache都要好，那就是它不但可以存储任意的数据，而且没有网络存取的延迟。因此，local cache的数据查询更快。考虑把highly</p>\n<p>common的数据放在local cache中吧。如果每个页面都需要加载一些数量较少的数据，可以考虑把它们放在local cached。</p>\n<p>3）local cache缺少集体失效（group invalidation）的特性。在memcached集群中，删除或更新一个key会让所有的观察者觉察到。但是在local cache中, 我们只能通知所有的服务器</p>\n<p>刷新cache（很慢，不具扩展性）或者仅仅依赖缓存超时失效机制。</p>\n<p>11、memcached的cache机制是怎样的？</p>\n<p>Memcached主要的cache机制是LRU（最近最少用）算法+超时失效。当您存数据到memcached中，可以指定该数据在缓存中可以呆多久Which is forever, or some time in the</p>\n<p>future。如果memcached的内存不够用了，过期的slabs会优先被替换，接着就轮到最老的未被使用的slabs。</p>\n<p>12、memcached如何实现冗余机制？</p>\n<p>不实现！Memcached应该是应用的缓存层，从设计本身来京就不带有任何冗余机制。如果一个memcached节点失去了所有数据，应该可以从数据源（比如数据库）再次获取到数据。应</p>\n<p>用系统应该可以容忍节点的失效。如果担心节点失效会大大加重数据库的负担，那么可以采取一些办法。比如您可以增加更多的节点（来减少丢失一个节点的影响），热备节点（在其他节</p>\n<p>点down了的时候接管IP）等等。</p>\n<p>13、memcached如何处理容错的？</p>\n<p>在节点失效的情况下，集群没有必要做任何容错处理。如果发生了节点失效，应对的措施完全取决于用户。</p>\n<p>节点失效时，下面列出几种方案供您选择：</p>\n<p>1）忽略它！ 在失效节点被恢复或替换之前，还有很多其他节点可以应对节点失效带来的影响。</p>\n<p>2）把失效的节点从节点列表中移除。做这个操作千万要小心！在默认情况下（余数式哈希算法），客户端添加或移除节点，会导致所有的缓存数据不可用！因为哈希参照的节点列表变化</p>\n<p>了，大部分key会因为哈希值的改变而被映射到（与原来）不同的节点上。</p>\n<p>3）启动热备节点，接管失效节点所占用的IP。这样可以防止哈希紊乱（hashing chaos）。</p>\n<p>4）如果希望添加和移除节点，而不影响原先的哈希结果，可以使用一致性哈希算法（consistent hashing）。</p>\n<p>5）两次哈希（reshing）。当客户端存取数据时，如果发现一个节点down了，就再做一次哈希（哈希算法与前一次不同），重新选择另一个节点（需要注意的时，客户端并没有把down</p>\n<p>的节点从节点列表中移除，下次还是有可能先哈希到它）。如果某个节点时好时坏，两次哈希的方法就有风险了，好的节点和坏的节点上都可能存在脏数据（stale data）。</p>\n<p>14、如何将memcached中item批量导入导出？</p>\n<p>不应该这样做！Memcached是一个非阻塞的服务器。任何可能导致memcached暂停或瞬时拒绝服务的操作都应该值得深思熟虑。向memcached中批量导入数据往往不是您真正想要</p>\n<p>的！想象看，如果缓存数据在导出导入之间发生了变化，您就需要处理脏数据了；如果缓存数据在导出导入之间过期了，您又怎么处理这些数据呢？</p>\n<p>因此，批量导出导入数据并不像想象中的那么有用。不过在一个场景倒是很有用。如果您有大量的从不变化 的数据，并且希望缓存很快热（warm）起来，批量导入缓存数据是很有帮助</p>\n<p>的。</p>\n<p>15、但是我确实需要把memcached中的item批量导出导入，怎么办？？</p>\n<p>如果需要批量导出和导入，最可能的原因一般是重新生成缓存数据需要消耗很长的时间或者数据库坏了让您饱受痛苦。</p>\n<p>如果一个memcached节点down了让您很痛苦，那么必须对数据库做一些优化工作。比如处理”惊群”问题（ memcached节点都失效了，反复的查询让数据库不堪重负）或者存在优化不</p>\n<p>好的查询等。Memcached 并不是逃避优化查询的借口和方案。</p>\n<p>这里给出一些提示：</p>\n<p>使用MogileFS（或者CouchDB等类似的软件）在存储item，把item计算出来并dump到磁盘上。MogileFS可以很方便地覆写item，并提供快速地访问。甚至可以把MogileFS中的item</p>\n<p>缓存在memcached中，这样可以加快读取速度。 MogileFS+Memcached的组合可以加快缓存不命中时的响应速度，提高网站的可用性。</p>\n<p>重新使用MySQL。MySQL的 InnoDB主键查询速度非常快。如果大部分缓存数据都可以放到VARCHAR字段中，那么主键查询的性能将更好。从memcached中按key查询几乎等价于</p>\n<p>MySQL的主键查询：将key 哈希到64-bit的整数，然后将数据存储到MySQL中。您可以把原始（不做哈希）的key存储都普通的字段中，然后建立二级索引来加快查询…key被动地失效，</p>\n<p>批量删除失效的key，等等。</p>\n<p>16、memcached是如何做身份验证的？</p>\n<p>没有身份认证机制！memcached是运行在应用下层的软件（身份验证应该是应用上层的职责）。memcached的客户端和服务器端之所以是轻量级的，部分原因就是完全没有实现身份验</p>\n<p>证机制。这样，memcached可以很快地创建新连接，服务器端也无需任何配置。如果您希望限制访问，您可以使用防火墙，或者让memcached监听unix domain socket。</p>\n<p>17、memcached的多线程是什么？如何使用它们？</p>\n<p>线程就是定律（threads rule）！在Steven Grimm和Facebook的努力下，memcached 1.2及更高版本拥有了多线程模式。多线程模式允许memcached能够充分利用多个CPU，并在</p>\n<p>CPU之间共享所有的缓存数据。memcached使用一种简单的锁机制来保证数据更新操作的互斥。相比在同一个物理机器上运行多个memcached实例，这种方式能够更有效地处理multi</p>\n<p>gets。如果系统的负载并不重，那么不需要启用多线程工作模式。如果您在运行一个拥有大规模硬件的、庞大的网站，将体验到看到多线程的好处。更多信息请参见：</p>\n<p><a href=\"http://code.sixapart.com/svn/memcached/trunk/server/doc/threads.txt\">http://code.sixapart.com/svn/memcached/trunk/server/doc/threads.txt</a> 。</p>\n<p>简单地总结一下：命令解析（memcached在这里花了大部分时间）可以运行在多线程模式下。memcached内部对数据的操作是基于很多全局锁的（因此这部分工作不是多线程的）。未</p>\n<p>来对多线程模式的改进，将移除大量的全局锁，提高memcached在负载极高的场景下的性能。</p>\n<p>18、memcached能接受的key的最大长度是多少？</p>\n<p>memcached能接受的key的最大长度是250个字符。需要注意的是，250是memcached服务器端内部的限制。如果使用的Memcached客户端支持”key的前缀”或类似特性，那么key</p>\n<p>（前缀+原始key）的最大长度是可以超过250个字符的。推荐使用较短的key，这样可以节省内存和带宽。</p>\n<p>19、memcached对item的过期时间有什么限制？</p>\n<p>item对象的过期时间最长可以达到30天。memcached把传入的过期时间（时间段）解释成时间点后，一旦到了这个时间点，memcached就把item置为失效状态，这是一个简单但</p>\n<p>obscure的机制。</p>\n<p>20、memcached最大能存储多大的单个item？</p>\n<p>memcached最大能存储1MB的单个item。如果需要被缓存的数据大于1MB，可以考虑在客户端压缩或拆分到多个key中。</p>\n<p>21、为什么单个item的大小被限制在1M byte之内？</p>\n<p>简单的回答：因为内存分配器的算法就是这样的。</p>\n<p>详细的回答：</p>\n<p>1）Memcached的内存存储引擎，使用slabs来管理内存。内存被分成大小不等的slabs chunks（先分成大小相等的slabs，然后每个slab被分成大小相等chunks，不同slab的chunk大小</p>\n<p>是不相等的）。chunk的大小依次从一个最小数开始，按某个因子增长，直到达到最大的可能值。如果最小值为400B，最大值是1MB，因子是1.20，各个slab的chunk的大小依次是：</p>\n<p>slab1 - 400B；slab2 - 480B；slab3 - 576B …slab中chunk越大，它和前面的slab之间的间隙就越大。因此，最大值越大，内存利用率越低。Memcached必须为每个slab预先分配内</p>\n<p>存，因此如果设置了较小的因子和较大的最大值，会需要为Memcached提供更多的内存。</p>\n<p>2）不要尝试向memcached中存取很大的数据，例如把巨大的网页放到mencached中。因为将大数据load和unpack到内存中需要花费很长的时间，从而导致系统的性能反而不好。如果</p>\n<p>确实需要存储大于1MB的数据，可以修改slabs.c：POWER_BLOCK的值，然后重新编译memcached；或者使用低效的malloc/free。另外，可以使用数据库、MogileFS等方案代替</p>\n<p>Memcached系统。</p>\n<p>22、可以在不同的memcached节点上使用大小不等的缓存空间吗？如果这么做之后，memcached能够更有效地使用内存吗？</p>\n<p>Memcache客户端仅根据哈希算法来决定将某个key存储在哪个节点上，而不考虑节点的内存大小。因此，可以在不同的节点上使用大小不等的内存作为缓存空间。但是一般可以这样做</p>\n<p>：拥有较多内存的节点上可以运行多个memcached实例，每个实例使用的内存跟其他节点上的实例相同。</p>\n<p>23、什么是二进制协议，是否需要关注？</p>\n<p>二进制协议尝试为端提供一个更有效的、可靠的协议，减少客户端/服务器端因处理协议而产生的CPU时间。根据Facebook的测试，解析ASCII协议是memcached中消耗CPU时间最多的</p>\n<p>环节。</p>\n<p>24、memcached的内存分配器是如何工作的？为什么不适用malloc/free！？为何要使用slabs？</p>\n<p>实际上，这是一个编译时选项。默认会使用内部的slab分配器，而且确实应该使用内建的slab分配器。最早的时候，memcached只使用malloc/free来管理内存。然而，这种方式不能与</p>\n<p>OS的内存管理以前很好地工作。反复地malloc/free造成了内存碎片，OS最终花费大量的时间去查找连续的内存块来满足malloc的请求，而不是运行memcached进程。slab分配器就是</p>\n<p>为了解决这个问题而生的。内存被分配并划分成chunks，一直被重复使用。因为内存被划分成大小不等的slabs，如果item的大小与被选择存放它的slab不是很合适的话，就会浪费一些内存。</p>\n<p>25、memcached是原子的吗？</p>\n<p>所有的被发送到memcached的单个命令是完全原子的。如果您针对同一份数据同时发送了一个set命令和一个get命令，它们不会影响对方。它们将被串行化、先后执行。即使在多线程模</p>\n<p>式，所有的命令都是原子的。然是，命令序列不是原子的。如果首先通过get命令获取了一个item，修改了它，然后再把它set回memcached，系统不保证这个item没有被其他进程</p>\n<p>（process，未必是操作系统中的进程）操作过。memcached 1.2.5以及更高版本，提供了gets和cas命令，它们可以解决上面的问题。如果使用gets命令查询某个key的item，</p>\n<p>memcached会返回该item当前值的唯一标识。如果客户端程序覆写了这个item并想把它写回到memcached中，可以通过cas命令把那个唯一标识一起发送给memcached。如果该item</p>\n<p>存放在memcached中的唯一标识与您提供的一致，写操作将会成功。如果另一个进程在这期间也修改了这个item，那么该item存放在memcached中的唯一标识将会改变，写操作就会</p>\n<p>失败。</p>\n<p>性能和客户端库方面的问题</p>\n<p>26、memcached没有我的database快，为什么？</p>\n<p>在一对一比较中，memcached可能没有SQL查询快。但是，这不是memcached的设计目标。Memcached的目标是可伸缩性。当连接和请求增加的时候，memcached的性能将比</p>\n<p>大多数数据库查询好。可以先在高负载的环境（并发的连接和请求）中测试您的代码，然后再决定memcached是否适合您。</p>\n<p>27、使用不同的客户端库，可以访问到memcached中相同的数据吗？</p>\n<p>从技术上说，是可以的。但是可能会遇到下面三个问题：</p>\n<p>1）不同的库采用不同的方式序列化数据。举个例子，perl的Cache::Memcached使用Storable来序列化结构复杂的数据（比如hash references, objects, 等）。其他语言的客户端库很</p>\n<p>可能不能读取这种格式的数据。如果您要存储复杂的数据并且想被多种客户端库读取，那么您应该以简单的string格式来存储，并且这种格式可以被JSON、XML等外部库解析。</p>\n<p>2）从某个客户端来的数据被压缩了，从另一个客户端来的却没被压缩。</p>\n<p>3）各个客户端库可能使用不同的哈希算法（阶段一哈希）。在连接到多个memcached服务器端的情况下，客户端库根据自身实现的哈希算法把key映射到某台memcached上。正是因为</p>\n<p>不同的客户端库使用不同的哈希算法，所以被Perl客户端库映射到memcached A的key，可能又会被Python客户端库映射到memcached B，等等。Perl客户端库还允许为每台</p>\n<p>memcached指定不同的权重（weight），这也是导致这个问题的一个因素。</p>\n<p>28、什么是一致性哈希的客户端？</p>\n<p>这里有一篇文章很好地解释了它的用处：<a href=\"http://www.last.fm/user/RJ/journal/2007/04/10/392555\">http://www.last.fm/user/RJ/journal/2007/04/10/392555</a> 。</p>\n<p>客户端可以通过”前缀”来给key设置一个域（命名空间）。例如，在一个共享主机的环境中，可以将客户姓名作为”前缀”，为key创建一个特定的域。在存储数据的时候，”前缀”可以用在</p>\n<p>key上，但是不应该参与哈希计算。目前，memcached自己还没有实现针对复杂结构数据的序列化方法，JSON则是一种被广泛使用的对象序列化格式。</p>\n<p>哈希 / 键分布</p>\n<p>29、什么时候失效的数据项会从缓存中删除？</p>\n<p>memcached 使用懒失效，当客户端请求数据项时， memcached 在返回数据前会检查失效时间来确定数据项是否已经失效。同样地，当添加一个新的数据项时，如果缓存已经满了， memcached 就会先替换失效的数据项，然后才是缓存中最少使用的数据项。</p>\n<p>命名空间</p>\n<p>30、memcached 不支持命名空间。以下提供几种模仿命名空间的方式：</p>\n<p>1）用键的前缀模仿命名空间：在真实的键之前加入有意义的前缀。</p>\n<p>2）用命名空间删除数据项：尽管 memcached 不支持使用任何类型的通配符或命名空间来完成删除操作，但是可以采用一些技巧来替代：</p>\n<p>在 PHP 中使用一个叫 foo 的命名空间：$ns_key = $memcache-&gt;get(“foo_namespace_key”);</p>\n<p>// if not set, initialize it</p>\n<p>if($ns_key=false) $memcache-&gt;set(“foo_namespace_key”, rand(1, 10000));</p>\n<p>$my<em>key = “foo</em>“.$ns_key.”_12345”;</p>\n<p>清除命名空间：$memcache-&gt;increment(“foo_namespace_key”);</p>\n<p>应用设计</p>\n<p>31、在设计应用时，可以通过Memcached缓存那些内容？</p>\n<p>1）缓存简单的查询结果：查询缓存存储了给定查询语句对应的整个结果集，最合适缓存那些经常被用到，但不会改变的 SQL 语句对查询到的结果集，比如载入特定的过滤内容。</p>\n<p>$key = md5(‘SELECT * FROM rest_of_sql_statement_goes_here’);</p>\n<p>if ($memcache-&gt;get($key)) {</p>\n<pre><code>` return $memcache-&gt;get($key);`\n</code></pre><p>}else {</p>\n<pre><code>` // Run the query and transform the result data into your final dataset form`\n\n` $result = $query_results_mangled_into_most_likely_an_array`\n\n ` $memcache-&gt;set($key, $result, TRUE, 86400); // Store the result of the query for a day`\n\n` return $result;`\n</code></pre><p>}</p>\n<p>记住，如果查询语句对应的结果集改变，该结果集不会展现出来。这种方法不总是有用，但它确实让工作变得比较快。</p>\n<p>2）缓存简单的基于行的查询结果：基于行的缓存会检查缓存数据key的列表，那些在缓存中的行可以直接被取出，不在缓存中的行将会从数据库中取出并以唯一的键为标识缓存起来，最</p>\n<p>后加入到最终的数据集中返回。随着时间的推移，大多数数据都会被缓存，这也意味着相比与数据库，查询语句会更多地从 memcached 中得到数据行。如果数据是相当静态的，我们可</p>\n<p>以设置一个较长的缓存时间。</p>\n<p>基于行的缓存模式对下面这种搜索情况特别有用：数据集本身很大或是数据集是从多张表中得到，而数据集取决于查询的输入参数但是查询的结果集之间的有重复部分。</p>\n<p>比如，如果你有用户 A ， B ， C ， D ， E 的数据集。你去点击一张显示用户 A ， B ， E 信息的页面。首先， memcached 得到 3 个不同的键，每个对应一个用户去缓存中查找，全部未</p>\n<p>命中。然后就到数据库中用 SQL 查询得到 3 个用户的数据行，并缓存他们。</p>\n<p>现在，你又去点击另一张显示显示 C ， D ， E 信息的页面。当你去查找 memcached 时， C ， D 的数据并没有被命中，但我们命中了 E 的数据。然后从数据库得到 C ， D 的行数据，缓</p>\n<p>存在 memcached 中。至此以后，无论这些用户信息怎样地排列组合，任何关于 A ， B ， C ， D ， E 信息的页面都可以从 memcached 得到数据了。</p>\n<p>3）缓存的不只是 SQL 数据，可以缓存最终完成的部分显示页面，以节省CPU计算时间</p>\n<p>例如正在制作一张显示用户信息的页面，你可能得到一段关于用户的信息（姓名，生日，家庭住址，简介），然后你可能会将 XML 格式的简介信息转化为 HTML 格式或做其他的一些工</p>\n<p>作。相比单独存储这些属性，你可能更愿意存储经过渲染的数据块。那时你就可以简单地取出被预处理后的 HTML 直接填充在页面中，这样节省了宝贵的 CPU 时间。</p>\n<p>32、使用分层的缓存</p>\n<p>memcached 可以高速处理大量的缓存数据，但是还是要根据系统的情况考虑维护多层的缓存结构。例如除了memcached缓存之外，还可以通过本地缓存（如ehcache、oscache等）建</p>\n<p>立起多级缓存。例如，可以采用本地缓存缓存一些基本数据，例如少量但访问频繁的数据（如产品分类，连接信息，服务器状态变量，应用配置变量等），缓存这些数据并让他们尽可能的</p>\n<p>接近处理器是有意义的 , 这样可以帮助减少生成页面的时间，并且在 memcached 失效的情况下可以增加可靠性。</p>\n<p>33、当数据更新时需要更新缓存</p>\n<p>用户编辑了自己的信息，当保存信息到数据库时，需要更新缓存中的数据或是简单地删除老的数据。如果马上更新数据，要防止从数据库读取那些刚刚更新过的数据。当用户习惯性地重新</p>\n<p>载入自己的用户信息来确认是否修改成功时，数据将从缓存中直接取出，这时他们获得了最新的数据。</p>\n<p>34、模拟带锁的添加命令</p>\n<p>如果你实在需要锁，你可以通过“添加”命令模仿锁的功能。尽管在未命中的情况下它不是那么有用，但如果你用它缓存平常的数据（应用服务器池的元数据）那还是有用的。</p>\n<p>比如，你要更新键 A 。</p>\n<ol>\n<li><p>添加一个 “lock:A” 的键，这个键有一个持续几秒的过期时间（足够长以使你能完成计算和更新，也不要很长，因为如果锁进程挂了，这个键不会立即释放）</p>\n</li>\n<li><p>如果添加操作成功了，你就拥有了锁：从缓存获取键 A 的数据；利用客户端程序更改数据；更新缓存键 A 的数据；删除键 “lock:A” 。如果你不需要立即再次更新，就让它存活直到失效。</p>\n</li>\n<li><p>如果添加操作失败，说明有人获取了锁。这时让应用做些合适的事，比如返回老数据，等待后重试，或是其他的。</p>\n</li>\n</ol>\n<p>以上这些操作类似 MySQL 将 GET_LOCK 的 timeout 值设置成 0 。没有办法在 memcached 中通过互斥锁模拟 GET_LOCK() 的 timeout 操作。</p>\n<p>35、预热你的缓存</p>\n<p>如果你有一个很高访问率的站点，并且你正想加入故障恢复功能或是其他全新的功能，你最终可能会碰到空缓存的问题。一开始缓存是空的，然后一大群人点击你的站点，在填充缓存的过</p>\n<p>程中，你的数据库可能会承受不住压力。为了解决这一问题，你可以试试任何可行的方法来 “ 温暖 “ 你的Memcached。方法：可以写一些脚本来缓存通用的页面；也可以写一个命令行工</p>\n<p>具来填充缓存。你可以在高峰时刻在缓存里填充一些内容。</p>\n"},{"title":"Mysql 文章","date":"2016-03-15T10:01:26.000Z","_content":"\nMysql 索引原理: <http://www.admin10000.com/document/5372.html>\n\n","source":"_posts/Mysql-文章.md","raw":"---\ntitle: Mysql 文章\ndate: 2016-03-15 18:01:26\ntags: mysql\n---\n\nMysql 索引原理: <http://www.admin10000.com/document/5372.html>\n\n","slug":"Mysql-文章","published":1,"updated":"2016-03-15T10:07:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cilt9a4t60002rxzj2v4zwhk2","content":"<p>Mysql 索引原理: <a href=\"http://www.admin10000.com/document/5372.html\" target=\"_blank\" rel=\"external\">http://www.admin10000.com/document/5372.html</a></p>\n","excerpt":"","more":"<p>Mysql 索引原理: <a href=\"http://www.admin10000.com/document/5372.html\">http://www.admin10000.com/document/5372.html</a></p>\n"},{"title":"Mysql 索引最左原则","date":"2016-03-15T03:08:37.000Z","_content":"\n### 能用到索引或者索引部分\n\n * 联合索引全字段匹配；如: where a=1 and b=2\n * 联合索引左边字段匹配；如: where a=1（索引是a，b）\n * 联合索引左边字段范围查询, 范围查询截断了索引的使用，\n \t* 如: where a < 100 and b=1（索引是a，b），只用到索引的a部分，b部分不起作用；\n\t* 如: where a = 100 and b>1（索引是a，b），用到了整个索引\n * 索引的模糊查询，可以用到索引的部分；如 where a like 'abc%'\n * IN 一般情况下是算作精确查询里。\n * 联合索引的使用场景还有 where + order by。\n  \n","source":"_posts/Mysql-最左原则.md","raw":"---\ntitle: Mysql 索引最左原则\ndate: 2016-03-15 11:08:37\ntags: mysql\ncategories: mysql\n---\n\n### 能用到索引或者索引部分\n\n * 联合索引全字段匹配；如: where a=1 and b=2\n * 联合索引左边字段匹配；如: where a=1（索引是a，b）\n * 联合索引左边字段范围查询, 范围查询截断了索引的使用，\n \t* 如: where a < 100 and b=1（索引是a，b），只用到索引的a部分，b部分不起作用；\n\t* 如: where a = 100 and b>1（索引是a，b），用到了整个索引\n * 索引的模糊查询，可以用到索引的部分；如 where a like 'abc%'\n * IN 一般情况下是算作精确查询里。\n * 联合索引的使用场景还有 where + order by。\n  \n","slug":"Mysql-最左原则","published":1,"updated":"2016-03-15T10:23:29.000Z","_id":"cilt9a4th0004rxzjaihrhoe5","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"能用到索引或者索引部分\"><a href=\"#能用到索引或者索引部分\" class=\"headerlink\" title=\"能用到索引或者索引部分\"></a>能用到索引或者索引部分</h3><ul>\n<li>联合索引全字段匹配；如: where a=1 and b=2</li>\n<li>联合索引左边字段匹配；如: where a=1（索引是a，b）</li>\n<li>联合索引左边字段范围查询, 范围查询截断了索引的使用，<ul>\n<li>如: where a &lt; 100 and b=1（索引是a，b），只用到索引的a部分，b部分不起作用；<ul>\n<li>如: where a = 100 and b&gt;1（索引是a，b），用到了整个索引</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>索引的模糊查询，可以用到索引的部分；如 where a like ‘abc%’</li>\n<li>IN 一般情况下是算作精确查询里。</li>\n<li>联合索引的使用场景还有 where + order by。</li>\n</ul>\n","excerpt":"","more":"<h3 id=\"能用到索引或者索引部分\"><a href=\"#能用到索引或者索引部分\" class=\"headerlink\" title=\"能用到索引或者索引部分\"></a>能用到索引或者索引部分</h3><ul>\n<li>联合索引全字段匹配；如: where a=1 and b=2</li>\n<li>联合索引左边字段匹配；如: where a=1（索引是a，b）</li>\n<li>联合索引左边字段范围查询, 范围查询截断了索引的使用，<ul>\n<li>如: where a &lt; 100 and b=1（索引是a，b），只用到索引的a部分，b部分不起作用；<ul>\n<li>如: where a = 100 and b&gt;1（索引是a，b），用到了整个索引</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>索引的模糊查询，可以用到索引的部分；如 where a like ‘abc%’</li>\n<li>IN 一般情况下是算作精确查询里。</li>\n<li>联合索引的使用场景还有 where + order by。</li>\n</ul>\n"},{"title":"test.md","date":"2016-03-14T10:36:28.000Z","_content":"\n测试一下\n","source":"_posts/test-md.md","raw":"---\ntitle: test.md\ndate: 2016-03-14 18:36:28\ntags: [测试,mysql,haha]\ncategories: \n    - mysql\n---\n\n测试一下\n","slug":"test-md","published":1,"updated":"2016-03-15T04:11:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cilt9a4tk0005rxzjl53piu7d","content":"<p>测试一下</p>\n","excerpt":"","more":"<p>测试一下</p>\n"},{"title":"PHP convert string to utf8","date":"2016-03-15T08:08:45.000Z","_content":"    public function convertStringToUtf8($string)\n    {\n        $string = urldecode($string);\n        $encoding = mb_detect_encoding($string, array('ASCII', 'UTF-8', 'GB2312', 'GBK', 'BIG5'));\n        $string = mb_convert_encoding($string, 'UTF-8', $encoding);\n        $string = trim(str_replace('GB2312', 'utf-8', $string));//换xml类型编码\n        return $string;\n    }\n\n","source":"_posts/PHP-convert-string-to-utf8.md","raw":"---\ntitle: PHP convert string to utf8\ndate: 2016-03-15 16:08:45\ntags: php\ncategories: php\n---\n    public function convertStringToUtf8($string)\n    {\n        $string = urldecode($string);\n        $encoding = mb_detect_encoding($string, array('ASCII', 'UTF-8', 'GB2312', 'GBK', 'BIG5'));\n        $string = mb_convert_encoding($string, 'UTF-8', $encoding);\n        $string = trim(str_replace('GB2312', 'utf-8', $string));//换xml类型编码\n        return $string;\n    }\n\n","slug":"PHP-convert-string-to-utf8","published":1,"updated":"2016-03-15T08:12:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cilt9a4tr0008rxzj3yopzilh","content":"<pre><code>public function convertStringToUtf8($string)\n{\n    $string = urldecode($string);\n    $encoding = mb_detect_encoding($string, array(&apos;ASCII&apos;, &apos;UTF-8&apos;, &apos;GB2312&apos;, &apos;GBK&apos;, &apos;BIG5&apos;));\n    $string = mb_convert_encoding($string, &apos;UTF-8&apos;, $encoding);\n    $string = trim(str_replace(&apos;GB2312&apos;, &apos;utf-8&apos;, $string));//换xml类型编码\n    return $string;\n}\n</code></pre>","excerpt":"","more":"<pre><code>public function convertStringToUtf8($string)\n{\n    $string = urldecode($string);\n    $encoding = mb_detect_encoding($string, array(&apos;ASCII&apos;, &apos;UTF-8&apos;, &apos;GB2312&apos;, &apos;GBK&apos;, &apos;BIG5&apos;));\n    $string = mb_convert_encoding($string, &apos;UTF-8&apos;, $encoding);\n    $string = trim(str_replace(&apos;GB2312&apos;, &apos;utf-8&apos;, $string));//换xml类型编码\n    return $string;\n}\n</code></pre>"},{"title":"初学Hexo","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: 初学Hexo \n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2016-03-15T07:07:07.000Z","updated":"2016-03-15T07:07:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cilt9a4tu000arxzj2jsl11t6","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\">Deployment</a></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cilt9a4th0004rxzjaihrhoe5","category_id":"cilt9a4tp0006rxzj9hovlijk","_id":"cilt9a4u6000erxzjzjllsd0v"},{"post_id":"cilt9a4tk0005rxzjl53piu7d","category_id":"cilt9a4tp0006rxzj9hovlijk","_id":"cilt9a4ub000irxzj4hzokzv4"},{"post_id":"cilt9a4tr0008rxzj3yopzilh","category_id":"cilt9a4u7000frxzjs87tlmsv","_id":"cilt9a4ue000krxzjnrz8ftr9"}],"PostTag":[{"post_id":"cilt9a4sr0000rxzjqheduxzq","tag_id":"cilt9a4tc0003rxzjxhsj63b9","_id":"cilt9a4tt0009rxzjnifts9eg"},{"post_id":"cilt9a4t60002rxzj2v4zwhk2","tag_id":"cilt9a4tq0007rxzjjfbf393f","_id":"cilt9a4u6000drxzjui7khjo7"},{"post_id":"cilt9a4th0004rxzjaihrhoe5","tag_id":"cilt9a4tq0007rxzjjfbf393f","_id":"cilt9a4ua000hrxzjr48ge6ck"},{"post_id":"cilt9a4tk0005rxzjl53piu7d","tag_id":"cilt9a4u9000grxzjtz7b2he8","_id":"cilt9a4uk000nrxzj4r5r9g5v"},{"post_id":"cilt9a4tk0005rxzjl53piu7d","tag_id":"cilt9a4tq0007rxzjjfbf393f","_id":"cilt9a4uo000orxzjb0olmfx3"},{"post_id":"cilt9a4tk0005rxzjl53piu7d","tag_id":"cilt9a4uf000lrxzjjpzrc1cy","_id":"cilt9a4up000prxzjo6symlut"},{"post_id":"cilt9a4tr0008rxzj3yopzilh","tag_id":"cilt9a4ui000mrxzj1iglhi6o","_id":"cilt9a4up000qrxzjkyvjwdov"}],"Tag":[{"name":"memcache","_id":"cilt9a4tc0003rxzjxhsj63b9"},{"name":"mysql","_id":"cilt9a4tq0007rxzjjfbf393f"},{"name":"测试","_id":"cilt9a4u9000grxzjtz7b2he8"},{"name":"haha","_id":"cilt9a4uf000lrxzjjpzrc1cy"},{"name":"php","_id":"cilt9a4ui000mrxzj1iglhi6o"}]}}